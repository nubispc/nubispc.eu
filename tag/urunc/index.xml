<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Urunc | Nubificus</title>
    <link>/tag/urunc/</link>
      <atom:link href="/tag/urunc/index.xml" rel="self" type="application/rss+xml" />
    <description>Urunc</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 11 Feb 2026 00:22:12 +0000</lastBuildDate>
    <image>
      <url>/media/logo_hu_f553cb9eef83bc41.png</url>
      <title>Urunc</title>
      <link>/tag/urunc/</link>
    </image>
    
    <item>
      <title>AI Agents? Not on my host</title>
      <link>/blog/urunc_agent/</link>
      <pubDate>Wed, 11 Feb 2026 00:22:12 +0000</pubDate>
      <guid>/blog/urunc_agent/</guid>
      <description>&lt;p&gt;Over the past few years, Large Language Models (LLMs) have changed how we
interact with computers. Instead of navigating interfaces or reading
documentation, we simply describe what we want in natural language.&lt;/p&gt;
&lt;p&gt;The next step, agentic AI, goes further: Agents do not just respond to
questions; they &lt;em&gt;act&lt;/em&gt;. They write code, build projects, run tests, and
can execute programs directly on our systems. And that is where things become
interesting, and risky!&lt;/p&gt;
&lt;p&gt;An AI agent is no longer &amp;ldquo;just a chatbot&amp;rdquo;. It becomes an
autonomous program executing arbitrary instructions on our system.
That raises a simple but important question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Would we run arbitrary, dynamically generated, unaudited code directly on our host system?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Probably not. Yet this is exactly what we allow when we let agents execute
commands without isolation.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s be safe and isolate AI agent execution using microVMs, but with
the familiar container. workflows. In this post, we will see how we can
&lt;code&gt;docker build&lt;/code&gt; and &lt;code&gt;docker run&lt;/code&gt; a microVM and run the agent inside it.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#isolating-ai-agents-execution-with-urunc&#34;&gt;Jump to the instructions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-threat-model-treat-agents-as-untrusted-code&#34;&gt;The Threat Model: Treat Agents as Untrusted Code&lt;/h2&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/evil_agent.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;Initially, LLMs were used in a simple request-response pattern: we asked
questions and received answers. In software development, those answers often
included code snippets or shell commands that we manually copied from the
browser and pasted into our editor or terminal.&lt;/p&gt;
&lt;p&gt;AI agents remove the middle (hu)man. Instead of suggesting commands, they
execute them. Instead of proposing code, they write it directly to disk.
However, this also removes the audit step (if anyone was actually doing it) when
copying commands or code from the browser.&lt;/p&gt;
&lt;p&gt;As a result, agents can execute the instructions they receive directly.
They can read and write
files, execute arbitrary shell commands, create and run new applications,
modify system configuration and even interact with external services; all
without explicit human review. And that can turn ugly very quickly.&lt;/p&gt;
&lt;p&gt;Agents do not rely only on user input. They also consume content from external
sources (repositories, documentation pages, forums, blogs, etc.).  They cannot
reliably distinguish between safe and harmful instructions; they simply follow
what appears relevant in the current context. Therefore, what an agent executes
on our machine can be highly influenced from external (and sometimes) malicious
sources.&lt;/p&gt;
&lt;p&gt;An example of the above scenario is &lt;a href=&#34;https://x.com/theonejvo/status/2015892980851474595&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a recent backdoor in a Skill for
openclaw&lt;/a&gt;.  In fact, &lt;a href=&#34;https://snyk.io/blog/toxicskills-malicious-ai-agent-skills-clawhub/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Snyk
published research
&lt;/a&gt; showing
that 36.82% of AI agent &amp;ldquo;skills&amp;rdquo; contained at least one security flaw.  Even
setting aside the &lt;a href=&#34;https://www.theregister.com/2026/02/05/openclaw_skills_marketplace_leaky_security/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;security hole called
openclaw&lt;/a&gt;,
both &lt;a href=&#34;https://claude.com/blog/cowork-research-preview&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anthropic&lt;/a&gt; and
&lt;a href=&#34;https://openai.com/index/hardening-atlas-against-prompt-injection/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI&lt;/a&gt;
have publicly acknowledged that prompt injection attacks remain a real and
unresolved challenge in agent security.&lt;/p&gt;
&lt;p&gt;From a systems perspective, once an agent can execute code, it effectively
becomes an untrusted program running on our system. This is not fundamentally
different from the cloud model, where users submit arbitrary workloads and
cloud providers must isolate and protect the infrastructure and other tenants
from potentially malicious or buggy code.&lt;/p&gt;
&lt;p&gt;Some agents attempt to mitigate this risk by restricting file access,
limiting which commands can be executed, or running them inside some form of sandbox.
However, these controls are often
implemented at the application level. They may be bypassed due to bugs,
or misconfigurations, or simply because the agent itself is closed-source and
opaque. In practice, we are asked to trust that the agent will respect the
boundaries we configure.&lt;/p&gt;
&lt;p&gt;But cloud providers do not rely on trust when running untrusted workloads. They
enforce strong isolation boundaries (from containers to VMs). If they do so,
we should not let AI agents run freely on our host systems either.&lt;/p&gt;
&lt;h2 id=&#34;workload-isolation&#34;&gt;Workload isolation&lt;/h2&gt;
&lt;p&gt;Fortunately, isolating untrusted workloads is a well-studied problem and there
are various mechanisms we can use.&lt;/p&gt;
&lt;h3 id=&#34;containers&#34;&gt;Containers&lt;/h3&gt;
&lt;p&gt;Containers have become the de facto packaging and deployment mechanism for
cloud applications. They restrict an application&amp;rsquo;s access to the host
using Linux kernel features such as namespaces, cgroups,
capabilities, seccomp and others. They are lightweight, easy to use and
distribute, and therefore a good candidate for packaging and creating a restricted
execution environment for an AI agent.&lt;/p&gt;
&lt;p&gt;However, all containers on a host share the same kernel.&lt;/p&gt;
&lt;p&gt;While this may not pose a threat in some scenarios, it can be a serious risk
under the threat model described above. A single vulnerability in the kernel or
container runtime can potentially lead to container escapes.&lt;/p&gt;
&lt;h3 id=&#34;virtual-machines&#34;&gt;Virtual Machines&lt;/h3&gt;
&lt;p&gt;Virtual Machines (VMs) provide the strongest isolation boundary available on a single
host. Using hardware virtualization features, hypervisors create an environment
where a separate operating system can boot. Applications inside the VM interact
only with the guest kernel, not the host kernel. This creates a much stronger
separation.&lt;/p&gt;
&lt;p&gt;Traditionally, VMs came with performance overhead and slow boot times.
but the introduction of microVMs in recent years has changed that.
Unlike traditional VMs, microVMs make use of specific devices and configurations
to decrease their size and overhead. This has led to the adoption of microVMs
in serverless and multi-tenant cloud environments.&lt;/p&gt;
&lt;p&gt;On the other hand, (micro)VMs typically increase the operational complexity and
their day-to-day workflow does not match the container UX. (Micro)VMs require a
kernel and a root filesystem to boot, and tasks like attaching volumes and
setting up networking with Internet access typically involve extra steps.&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/app_containers_vms.svg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;h3 id=&#34;sandboxed-containers&#34;&gt;Sandboxed Containers&lt;/h3&gt;
&lt;p&gt;Of course, people have recognized that containers are great for packaging and
deploying applications, but microVMs offer stronger isolation. As a result,
solutions that combine these technologies, as well as other software-based
sandboxing approaches, have emerged. These solutions are referred to as
sandboxed container runtimes and they aim to provide stronger isolation while
preserving the familiar container workflows and tooling.&lt;/p&gt;
&lt;p&gt;In the case of microVMs, &lt;a href=&#34;https://katacontainers.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kata Containers&lt;/a&gt; is a
container runtime that, instead of directly spawning a container on the host,
spins up a microVM and runs the container inside it.  &lt;a href=&#34;https://katacontainers.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kata
Containers&lt;/a&gt; provide its own Linux kernel and root
filesystem, but users can configure the runtime to use a custom kernel and/or
rootfs.&lt;/p&gt;
&lt;p&gt;In the case of software-based sandboxes, &lt;a href=&#34;https://gvisor.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gVisor&lt;/a&gt; is a
container runtime that spawns an application kernel alongside the container.
This application kernel mediates between the container and the host system: it
intercepts system calls from the container, implements as many as possible
itself, and forwards the rest (for example, I/O-related calls) to the host.&lt;/p&gt;
&lt;p&gt;In this post, we will discuss the new kid on the block in sandboxed container
runtimes: &lt;a href=&#34;https://urunc.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc&lt;/a&gt;. Unlike the runtimes mentioned above,
&lt;code&gt;urunc&lt;/code&gt; is designed to isolate only the untrusted parts of a deployment. In a
Kubernetes context, this means that instead of running the entire pod in a
sandbox, only the untrusted parts run in a sandbox inside the pod,
alongside trusted components that run as regular containers.&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/runtimes.svg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;h2 id=&#34;the-spawning-time-of-containers-with-vm-level-isolation-and-minimal-overhead&#34;&gt;The spawning time of containers with VM level isolation and minimal overhead&lt;/h2&gt;
&lt;p&gt;The idea behind &lt;code&gt;urunc&lt;/code&gt; is that the sandbox should be as small as possible and
contain only the untrusted parts of a deployment. Therefore, &lt;code&gt;urunc&lt;/code&gt; does not
require any additional components running inside or alongside the sandbox.
Subsequently, it can support both software- and VM-based sandboxes, along with a
variety of guest types, from unikernels to more general-purpose kernels like
Linux and BSD.  Think of it as spawning a microVM using the container&amp;rsquo;s rootfs ,
with the container entrypoint running as &lt;code&gt;init&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The sandbox, that &lt;code&gt;urunc&lt;/code&gt; creates, runs as a Linux container and it
integrates seamlessly with container workflows. We can create, start containers
as simply as &lt;code&gt;docker run&lt;/code&gt;, get network access as a container, and
attach volumes as with any other container.&lt;/p&gt;
&lt;p&gt;Thanks to its design &lt;code&gt;urunc&lt;/code&gt; can achieve comparable spawn times to normal
containers and introduces minimal overhead. Check out the past &lt;a href=&#34;https://github.com/urunc-dev/urunc?tab=readme-ov-file#publications-and-talks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;talks and
publications&lt;/a&gt;
for comparisons with other sandboxed container runtimes.&lt;/p&gt;
&lt;p&gt;In the context of agents, &lt;code&gt;urunc&lt;/code&gt; can be used in two ways:
a) as a sandbox for the entire agent. or b) as a sandbox for a
specific application executions triggered by the agent.&lt;/p&gt;
&lt;p&gt;In this post we will describe the first approach and run an agent inside a
&lt;code&gt;urunc&lt;/code&gt; container. Stay tuned for the second approach.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s try it out.&lt;/p&gt;
&lt;h2 id=&#34;isolating-ai-agents-execution-with-urunc&#34;&gt;Isolating AI agents execution with urunc&lt;/h2&gt;
&lt;p&gt;To showcase how we can use &lt;code&gt;urunc&lt;/code&gt; to isolate an AI agent, we will use as an
example &lt;a href=&#34;https://opencode.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;opencode&lt;/a&gt;, but the instructions below can be
adapted for any agent. Overall, we just need to set up the &lt;code&gt;urunc&lt;/code&gt; environment,
build the container images, and run them.&lt;/p&gt;
&lt;h3 id=&#34;step-0-setting-up-the-environment&#34;&gt;Step 0: Setting up the environment&lt;/h3&gt;
&lt;p&gt;Assuming we already have a working docker / containerd installation, we can install
&lt;code&gt;urunc&lt;/code&gt; and its shim as easily as fetching the binaries from the latest release:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# or for the latest release&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;URUNC_VERSION&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;curl -L -s -o /dev/null -w &lt;span class=&#34;s1&#34;&gt;&amp;#39;%{url_effective}&amp;#39;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;https://github.com/urunc-dev/urunc/releases/latest&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep -oP &lt;span class=&#34;s2&#34;&gt;&amp;#34;v\d+\.\d+\.\d+&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sed &lt;span class=&#34;s1&#34;&gt;&amp;#39;s/v//&amp;#39;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;URUNC_BINARY_FILENAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;urunc_static_&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -q https://github.com/urunc-dev/urunc/releases/download/v&lt;span class=&#34;nv&#34;&gt;$URUNC_VERSION&lt;/span&gt;/&lt;span class=&#34;nv&#34;&gt;$URUNC_BINARY_FILENAME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x &lt;span class=&#34;nv&#34;&gt;$URUNC_BINARY_FILENAME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo mv &lt;span class=&#34;nv&#34;&gt;$URUNC_BINARY_FILENAME&lt;/span&gt; /usr/local/bin/urunc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And for &lt;code&gt;containerd-shim-urunc-v2&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;CONTAINERD_BINARY_FILENAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;containerd-shim-urunc-v2_static_&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -q https://github.com/urunc-dev/urunc/releases/download/v&lt;span class=&#34;nv&#34;&gt;$URUNC_VERSION&lt;/span&gt;/&lt;span class=&#34;nv&#34;&gt;$CONTAINERD_BINARY_FILENAME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;chmod +x &lt;span class=&#34;nv&#34;&gt;$CONTAINERD_BINARY_FILENAME&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo mv &lt;span class=&#34;nv&#34;&gt;$CONTAINERD_BINARY_FILENAME&lt;/span&gt; /usr/local/bin/containerd-shim-urunc-v2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For more detailed installation instructions see the &lt;a href=&#34;https://urunc.io/installation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;installation guide of
&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt;. The guide contains also instructions
to download the &lt;a href=&#34;https://urunc.io/installation/#option-3-install-from-latest-artifacts-tip-of-the-main-branch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;latest build of the &lt;code&gt;main&lt;/code&gt;
branch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As previously mentioned, &lt;code&gt;urunc&lt;/code&gt; supports &lt;a href=&#34;https://urunc.io/#current-support-of-unikernels-and-vmsandbox-monitors&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a variety of software- and VM-based
sandboxes&lt;/a&gt;.
For simplicity, this post focuses on a VM-based sandbox using Linux and QEMU.
We will also use &lt;a href=&#34;https://virtio-fs.gitlab.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;virtiofs&lt;/a&gt; to share data
between the host and the VM. As a result, we will need to install QEMU and
virtiofsd.&lt;/p&gt;
&lt;p&gt;We can install them either via our distribution’s package manager or by
downloading pre-built artifacts from the
&lt;a href=&#34;https://github.com/urunc-dev/monitors-build&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;monitors-build&lt;/a&gt; repository. For
more details, refer to the &lt;a href=&#34;https://urunc.io/installation/#step-2-install-all-supported-monitors&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;respective section of the installation
guide&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-1-creating-the-container-image&#34;&gt;Step 1: Creating the Container image&lt;/h3&gt;
&lt;p&gt;In this step, we define the environment in which the agent will run. We will
do that with a &lt;code&gt;Containerfile&lt;/code&gt;. For example, we can create a Go dev environment
based on the container image of opencode with the following &lt;code&gt;Containerfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM ghcr.io/anomalyco/opencode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RUN apk add git go
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WORKDIR /app
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can build the container image with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f Containerfile -t go-dev-opencode:normal .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To make the container image above compatible with &lt;code&gt;urunc&lt;/code&gt;, we need to include a
Linux kernel for the VM and set a few &lt;code&gt;urunc&lt;/code&gt; -specific OCI annotations.  In
addition, to configure the execution environment inside the VM (UID/GID, working
directory, etc.), we will use a custom &lt;code&gt;init&lt;/code&gt; called
&lt;a href=&#34;https://github.com/nubificus/urunit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunit&lt;/a&gt;.
This is optional but recommended. As mentioned earlier, &lt;code&gt;urunc&lt;/code&gt; does not require
any additional components inside the sandbox; however, if our workload expects
to run in a specific setup (UID/GID, working directory, etc.), someone needs to
set this up, and that is what &lt;code&gt;urunit&lt;/code&gt; provides.&lt;/p&gt;
&lt;p&gt;While this may sound like a lot of work, we can handle it without installing
extra tooling by using &lt;a href=&#34;https://github.com/nubificus/bunny&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bunny&lt;/a&gt;.
It is a
buildkit frontend that works directly with
&lt;code&gt;docker build&lt;/code&gt;.
Bunny can parse two types of files: a) the standard &lt;code&gt;Containerfile&lt;/code&gt;
and b) a YAML-based file specific to &lt;code&gt;bunny&lt;/code&gt; called
&lt;a href=&#34;https://github.com/nubificus/bunny?tab=readme-ov-file#the-bunnyfile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bunnyfile&lt;/a&gt;.
Using either type, we can add the kernel, &lt;code&gt;urunit&lt;/code&gt; and set the required annotations.&lt;/p&gt;
&lt;h4 id=&#34;bunny-with-containerfile&#34;&gt;Bunny with Containerfile&lt;/h4&gt;
&lt;p&gt;For simplicity we have created a &lt;code&gt;bunny&lt;/code&gt; variant that can get an existing
&lt;code&gt;Containerfile&lt;/code&gt; and build an image compatible with &lt;code&gt;urunc&lt;/code&gt;.
To use it we simply need to prepend the following line in &lt;code&gt;Containerfile&lt;/code&gt;:
&lt;code&gt;#syntax=harbor.nbfc.io/nubificus/bunny:containerfile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The new &lt;code&gt;Containerfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#syntax=harbor.nbfc.io/nubificus/bunny:containerfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM ghcr.io/anomalyco/opencode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RUN apk add git go
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WORKDIR /app
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can build it exactly as before with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f Containerfile -t go-dev-opencode:containerfile .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;bunny-with-bunnyfile&#34;&gt;Bunny with bunnyfile&lt;/h4&gt;
&lt;p&gt;For users who want more control over the kernel and the &lt;code&gt;init&lt;/code&gt;, we recommend
using the &lt;code&gt;bunnyfile&lt;/code&gt; format. This approach involves two build steps, one for
the base container and one using &lt;code&gt;bunny&lt;/code&gt; to make the image &lt;code&gt;urunc&lt;/code&gt; compatible.
The first steps uses the standard &lt;code&gt;Containerfile&lt;/code&gt;, while the second uses a
&lt;code&gt;bunnyfile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We assume that the first step has been done using the &lt;code&gt;Containerfile&lt;/code&gt;
above. For the second build, we can use the following &lt;code&gt;bunnyfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#syntax=harbor.nbfc.io/nubificus/bunny:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;version: v0.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;platforms:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  framework: linux
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  monitor: qemu
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  architecture: x86
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rootfs:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  from: go-dev-opencode:normal
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  type: raw
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  include:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  - from: harbor.nbfc.io/nubificus/urunit:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    source: /urunit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    destination: /urunit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kernel:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  from: local
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  path: kernel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;entrypoint: [&amp;#34;/urunit&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmd: [&amp;#34;opencode&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the above &lt;code&gt;bunnyfile&lt;/code&gt;,  we specify:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a &lt;code&gt;urunc&lt;/code&gt; container image targeting Linux over Qemu in x86 architecture.&lt;/li&gt;
&lt;li&gt;with a rootfs based on the container image we created before appending the
&lt;code&gt;urunit&lt;/code&gt; binary from the latest &lt;code&gt;urunit&lt;/code&gt; container image.&lt;/li&gt;
&lt;li&gt;with a kernel which resides locally under the name &lt;code&gt;kernel&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;with &lt;code&gt;/urunit&lt;/code&gt; and &lt;code&gt;opencode&lt;/code&gt; as entrypoint and cmd respectively.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can build it simply with docker:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f bunnyfile -t go-dev-opencode:bunnyfile .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2-running-the-container&#34;&gt;Step 2: Running the container&lt;/h3&gt;
&lt;p&gt;To run the containers we built in the previous steps, we can simply:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -m 1024M --rm -it go-dev-opencode:normal
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and opencode TUI will open.&lt;/p&gt;
&lt;p&gt;Running a &lt;code&gt;urunc&lt;/code&gt; container follows the same workflow; simply add the &lt;code&gt;--runtime io.containerd.urunc.v2&lt;/code&gt; cli option when starting a container from either a
bunnyfile-based or Containerfile-based image.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -m 1024M --rm --runtime io.containerd.urunc.v2 -it go-dev-opencode:bunnyfile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;That&amp;rsquo;s it! We have created a VM that can run arbitrary workloads using the root
filesystem we defined when building the container image.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hint: Use &lt;a href=&#34;https://opencode.ai/docs/web/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the web interface of opencode&lt;/a&gt; and expose
its port to the host with &lt;code&gt;-p &amp;lt;PORT&amp;gt;:&amp;lt;PORT&amp;gt;&lt;/code&gt; to avoid issues with the console.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;step-3-sharing-data-with-the-host&#34;&gt;Step 3: Sharing data with the host&lt;/h3&gt;
&lt;p&gt;In a normal container we can share a host directory with the container with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -m 1024M --rm -v ${PWD}/mydir:/mydir -it go-dev-opencode:bunnyfile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In a &lt;code&gt;urunc&lt;/code&gt; container nothing changes, except of specifying the runtime:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -m 1024M --rm --runtime io.containerd.urunc.v2 -v ${PWD}/mydir:/mydir -it go-dev-opencode:bunnyfile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and now we have &lt;code&gt;mydir&lt;/code&gt; in the VM&amp;rsquo;s rootfs and everything is shared, but use
with caution.&lt;/p&gt;
&lt;h2 id=&#34;what-urunc-protects-us-from&#34;&gt;What &lt;code&gt;urunc&lt;/code&gt; protects us from&lt;/h2&gt;
&lt;p&gt;Like other sandboxed runtimes, &lt;code&gt;urunc&lt;/code&gt; isolates untrusted code from the host
system.  As a result, &lt;code&gt;urunc&lt;/code&gt; will protect our host&amp;rsquo;s filesystem, kernel and
other processes, making a container escape to the host significantly more difficult.&lt;/p&gt;
&lt;p&gt;However, isolation is not magic. If we explicitly share data or resources with
a &lt;code&gt;urunc&lt;/code&gt; container, that data is no longer protected. Untrusted code can still
delete files, leak data, or misuse whatever access we grant it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;urunc&lt;/code&gt; provides a strong boundary, but the security policy is still controlled
by us (the users).&lt;/p&gt;
&lt;h2 id=&#34;hands-on-example&#34;&gt;Hands-on example&lt;/h2&gt;
&lt;p&gt;As an example, we captured an end-to-end execution of opencode running inside
a QEMU VM with &lt;code&gt;urunc&lt;/code&gt;. In this demo, we use the container images built earlier
and instruct opencode to create a Go server that responds to HTTP requests with
random messages.We also share a directory with the &lt;code&gt;urunc&lt;/code&gt;container; within
that directory, opencode initializes a Git repository and commits the changes.&lt;/p&gt;
&lt;script src=&#34;https://asciinema.org/a/787412.js&#34; id=&#34;asciicast-787412&#34; async=&#34;true&#34;&gt;&lt;/script&gt;
&lt;h2 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;AI agents blur the line between &amp;ldquo;tool&amp;rdquo; and &amp;ldquo;program&amp;rdquo;. Once they execute
code, they should be treated as untrusted workloads.&lt;/p&gt;
&lt;p&gt;Containers made deployment easy, but for agentic execution, a shared kernel
might not be enough. Virtual machines provide the right boundary and with
sandboxed container runtimes like &lt;code&gt;urunc&lt;/code&gt;, they can be managed as easily as
containers.&lt;/p&gt;
&lt;p&gt;If agents are going to run code on our system, they should not run on our host.&lt;/p&gt;
&lt;p&gt;Use them with caution.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ContainerDays Hamburg 2025: Unikernel Deployment Made Easy: A CRI-Compatible Runtime for Secure Cloud Deployments</title>
      <link>/event/containerdays2025/</link>
      <pubDate>Wed, 03 Sep 2025 17:30:00 +0000</pubDate>
      <guid>/event/containerdays2025/</guid>
      <description>&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudkernels.net/posts/urunc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - A Container Runtime for Unikernels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudkernels.net/posts/wasm-urunc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebAssembly and urunc Integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Container Plumbing Days - urunc: A Container runtime for unikernels and single application kernels</title>
      <link>/event/containerplumbing2025/</link>
      <pubDate>Thu, 28 Aug 2025 13:50:00 +0000</pubDate>
      <guid>/event/containerplumbing2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cloud-native Summit Munich 2025: Isolating Workloads in Multi-Tenant Kubernetes Clusters</title>
      <link>/event/cloudnativesummit2025/</link>
      <pubDate>Tue, 04 Feb 2025 16:00:00 +0000</pubDate>
      <guid>/event/cloudnativesummit2025/</guid>
      <description>&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudkernels.net/posts/urunc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - A Container Runtime for Unikernels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudkernels.net/posts/wasm-urunc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebAssembly and urunc Integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>FOSDEM 2025: WASM Meets Unikernels - Secure and Efficient Cloud-Native Deployments</title>
      <link>/event/fosdem2025-1/</link>
      <pubDate>Sun, 02 Feb 2025 09:00:00 +0000</pubDate>
      <guid>/event/fosdem2025-1/</guid>
      <description>&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.cloudkernels.net/posts/wasm-urunc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WASM and urunc Integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;code--resources&#34;&gt;Code &amp;amp; Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/urunc-dev/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - Container Runtime Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nubificus/bunny&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bunny - Building Tool Repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>FOSDEM 2025: Less Overhead, Strong Isolation - Running Containers in Minimal Specialized Linux VMs</title>
      <link>/event/fosdem2025-2/</link>
      <pubDate>Sat, 01 Feb 2025 16:20:00 +0000</pubDate>
      <guid>/event/fosdem2025-2/</guid>
      <description>&lt;h2 id=&#34;code--resources&#34;&gt;Code &amp;amp; Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/urunc-dev/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - Container Runtime Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nubificus/bunny&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bunny - Kernel Building Tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sandboxing WASM with Unikernels for Secure Cloud-Native Deployments</title>
      <link>/blog/wasm-urunc/</link>
      <pubDate>Thu, 21 Nov 2024 15:22:12 +0000</pubDate>
      <guid>/blog/wasm-urunc/</guid>
      <description>&lt;p&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/images/web-assembly-logo.png#floatright&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;30%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;a href=&#34;https://webassembly.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebAssembly (WASM)&lt;/a&gt; is rapidly emerging as a
transformative technology in the cloud-native ecosystem. Its binary instruction
format, designed for execution on a stack-based Virtual Machine (VM), enables WASM
modules to run seamlessly on any platform, unlocking unprecedented portability.
Moreover, WASM promises near-native execution performance and enhanced security
due to its “sandboxed” execution model.&lt;/p&gt;
&lt;p&gt;A closer examination of WASM&amp;rsquo;s sandboxing reveals certain limitations.  In
WASM, modules execute within a stack-based VM that isolates them from direct
interaction with the external environment. Communication with the outside world
is mediated through imports and exports, with no direct access to system calls
or underlying resources. Instead, the WebAssembly System Interface (WASI)
employs a capability-based system to grant controlled access to external
resources. Simply put, the WASM sandbox is essentially a software construct
that enforces controlled interactions between the module and its environment.&lt;/p&gt;
&lt;p&gt;While this sandboxing model offers strong software-based isolation, it still
raises questions about the robustness of security, particularly given the
findings of several research papers on WASM’s security vulnerabilities. To
achieve stronger isolation, a more robust mechanism, such as hardware-based
virtualization, is necessary. By executing each WASM module within its own VM,
in the event of a WASM runtime escape, an attacker would also need to breach
the VM — a significantly more challenging exercise.&lt;/p&gt;
&lt;p&gt;On the other hand, VMs have the reputation of being heavyweight and unsuitable
for lightweight workloads, such as running individual WASM modules. The
overhead in terms of memory and CPU makes traditional virtualization
impractical for this purpose.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2451116.2451167&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unikernels&lt;/a&gt;, a technology
introduced in 2013 that has quietly matured over the years, could provide a
viable alternative to minimize this overhead. Unikernels are highly
specialized, lightweight operating system kernels designed to run a single
application efficiently, eliminating the overhead of general-purpose OSes. They
feature a minimal footprint, extremely fast boot times, and robust isolation.
However, unikernels have historically faced criticism for being difficult to
use, with application porting requiring significant effort.&lt;/p&gt;
&lt;p&gt;This is where WASM complements unikernels beautifully. WASM’s portable binary
representation is designed to execute on any compatible environment, including
unikernels. This means WASM modules can run on unikernels with minimal
adaptation, unlocking a powerful combination: the portability and flexibility
of WASM, paired with the lightweight, fast-booting, and hardware-isolated
properties of unikernel-based VMs.&lt;/p&gt;
&lt;p&gt;By combining these technologies, we achieve a compelling solution: WASM modules
running within small, fast, and truly isolated unikernel-powered VMs. This
approach delivers the best of both worlds: strong isolation through
virtualization and efficient resource utilization.&lt;/p&gt;
&lt;p&gt;Fortunately, we are not alone in this vision. Several projects have already
begun exploring this intersection of WASM, unikernels, and virtualization,
demonstrating the potential of this powerful synergy. Specifically:&lt;/p&gt;
&lt;p&gt;In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/mewz-project/mewz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mewz&lt;/a&gt; is a unikernel framework designed
to only run WASM applications.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/unikraft&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unikraft&lt;/a&gt;, an active unikernel project,
provides support for &lt;a href=&#34;https://github.com/unikraft/app-wamr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WAMR&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudius-systems/osv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSv&lt;/a&gt;, one of the most well known
unikernel framework supports the well known &lt;a href=&#34;https://github.com/cloudius-systems/osv-apps/tree/2347c09a7fb55e6e13474a83339d6f4e26e43c85/webassembly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wasmer
runtime&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/flavio/hermit-wasm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hermit-Wasm&lt;/a&gt; used
&lt;a href=&#34;https://github.com/ahmedelashouti/rusty-hermit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RustyHermit&lt;/a&gt;, a unikernel
written in Rust to execute WebAssembly applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, we can already execute WASM applications in unikernels. But how do we
manage these unikernels efficiently? Enter
&lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt;, a container runtime tailored
specifically for unikernels. As explained in a &lt;a href=&#34;/posts/urunc&#34;&gt;previous post&lt;/a&gt;,
&lt;code&gt;urunc&lt;/code&gt; functions as the &lt;code&gt;runc&lt;/code&gt; equivalent for unikernels. With &lt;code&gt;urunc&lt;/code&gt;, we can
deploy, execute, and manage unikernels as seamlessly as managing typical
containerized workloads.&lt;/p&gt;
&lt;p&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-logo.png#floatleft&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;20%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

Building on this foundation, we explored combining WASM, unikernels, and
&lt;code&gt;urunc&lt;/code&gt; to create a cohesive system stack that allows us to deploy, execute,
and manage WASM applications running on unikernels as easily as traditional
containers. To achieve this, we extended &lt;code&gt;urunc&lt;/code&gt; to support additional
unikernel frameworks, including &lt;a href=&#34;https://github.com/mewz-project/mewz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mewz&lt;/a&gt;
and &lt;a href=&#34;https://github.com/cloudius-systems/osv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OSv&lt;/a&gt;, alongside its existing
support for Unikraft. This diversity of unikernel frameworks gives us
flexibility in running WASM applications on top of various unikernel
environments, each offering unique advantages.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a closer look at each one of them.&lt;/p&gt;
&lt;h2 id=&#34;mewz&#34;&gt;Mewz&lt;/h2&gt;
&lt;p&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/images/mewz-logo.png#floatright&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;30%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;a href=&#34;https://github.com/mewz-project/mewz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mewz&lt;/a&gt; is a unikernel framework designed
to support ultra-lightweight, high-performance workloads. In contrast to other
WASM runtimes that execute on top of general purpose operating systems, Mewz is
designed as a specialized kernel where WASM applications can execute. In
addition, every WASM application executes on a separate Mewz instance,
maintaining the single-purpose notion of unikernels. This makes Mewz
particularly well-suited for scenarios where low latency and efficiency are
critical.&lt;/p&gt;
&lt;p&gt;According to the design of Mewz, the WASM application is transformed to an object
file which is directly linked against the Mewz kernel. Therefore, when the Mewz
kernel boots, it executes the linked WASM application.  Mewz has partial
support for &lt;a href=&#34;https://github.com/WebAssembly/WASI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WASI&lt;/a&gt; and it provides support
for networking and an in-memory, read-only filesystem. In addition, Mewz has
socket compatibility with
&lt;a href=&#34;https://github.com/WasmEdge/WasmEdge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WasmEdge&lt;/a&gt;,&lt;/p&gt;
&lt;h3 id=&#34;mewz-and-urunc&#34;&gt;Mewz and urunc&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Adding support for Mewz in &lt;code&gt;urunc&lt;/code&gt; is a straightforward task. Essentially,
to boot Mewz unikernels, we need to tweak a few parameters in the Qemu command.
This functionality will be available in the next planned release of &lt;code&gt;urunc&lt;/code&gt;. Until then,
we use the &lt;a href=&#34;https://github.com/nubificus/urunc/tree/mewz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;mewz&lt;/code&gt; branch&lt;/a&gt; in &lt;code&gt;urunc&lt;/code&gt; when building it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We build &lt;code&gt;urunc&lt;/code&gt; with Mewz support with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/nubificus/urunc.git -b mewz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run --rm -ti -v &lt;span class=&#34;nv&#34;&gt;$PWD&lt;/span&gt;/urunc:/urunc -w /urunc golang:1.23 bash -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;git config --global --add safe.directory /urunc &amp;amp;&amp;amp; make&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo make -C urunc install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Note: Please refer to &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc&lt;/a&gt; for more details
on installation and any relevant dependencies.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;building-mewz-unikernels-with-a-wasm-module&#34;&gt;Building Mewz unikernels with a WASM module&lt;/h3&gt;
&lt;p&gt;Mewz is built using &lt;a href=&#34;https://ziglang.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zig&lt;/a&gt; and it also requires
&lt;a href=&#34;https://github.com/mewz-project/wasker#how-to-run-wasker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wasker&lt;/a&gt; to transform
a WASM binary in an elf object. Mewz will link the WASM binary along with
its kernel and it will produce the unikernel. First step in this process is to create
the wasm app. We use the &lt;code&gt;app.wasm&lt;/code&gt; file built from the &lt;a href=&#34;https://github.com/mewz-project/mewz/tree/main/examples/hello_world&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mewz hello world
example&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to make the whole
process a bit simpler, we use the following Dockerfile to build the Mewz unikernel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;debian&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bookworm&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;builder&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ARG&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ZIG_VERSION&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.12&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;update&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;apt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;utils&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmake&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;libstdc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;essential&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;apt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;rm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;apt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lists&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SL&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ziglang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ZIG_VERSION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x86_64&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ZIG_VERSION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xJC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tmp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;mv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x86_64&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ZIG_VERSION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;usr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zig&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;curl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sSfL&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;project&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wasker&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;releases&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;download&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wasker&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linux&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uname&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gnu&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xzvC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;usr&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wasker&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clone&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;project&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;git&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;submodule&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;update&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;init&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scripts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;newlib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scripts&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lwip&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;WORKDIR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ENV&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/usr/bin/zig:${PATH}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;COPY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wasm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;RUN&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wasker&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wasm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;zig&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;build&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Dapp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=./&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;wasm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;o&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scratch&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;artifacts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;COPY&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;builder&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zig&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bin&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;elf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mewz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;elf&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can use the above Dockerfile to generate the Mewz unikernel binary with the
following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f Dockerfile -t mewz/builder  --target artifacts --output type=local,dest=./out .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above command will build the Mewz unikernel and use the &lt;code&gt;app.wasm&lt;/code&gt; file in
our current directory as the WASM module for the unikernel.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: As &lt;code&gt;app.wasm&lt;/code&gt; file, we used the &lt;a href=&#34;https://github.com/mewz-project/wasker/blob/main/helloworld.wat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;helloworld.wat&lt;/a&gt; file from wasker.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;However, Mewz produces an x86-64 image which Qemu refuses to load. For that
purpose, we can perform the following trick, where we overwrite the &lt;code&gt;e_machine&lt;/code&gt;
field of the Elf header to &lt;code&gt;EM_386&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;printf &amp;#39;\x03\x00&amp;#39; | dd of=out/mewz.elf bs=1 seek=18 count=2 conv=notrunc
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;packaging-mewz-unikernels-for-urunc&#34;&gt;Packaging Mewz unikernels for &lt;code&gt;urunc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;After building the Mewz unikernel, we need to package it as an OCI image in
order to deploy it over &lt;code&gt;urunc&lt;/code&gt;. For that purpose, we will use
&lt;a href=&#34;https://github.com/nubificus/pun&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pun&lt;/a&gt;, a tool we develop that uses &lt;a href=&#34;https://github.com/moby/buildkit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;buildkit&lt;/a&gt;
to package unikernels in OCI images.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s create the &lt;code&gt;Containerfile&lt;/code&gt; with all the information for &lt;code&gt;pun&lt;/code&gt; to
package the Mewz unikernel.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#syntax=harbor.nbfc.io/nubificus/pun:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM scratch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;COPY out/mewz.elf /unikernel/mewz.elf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.binary&amp;#34;=&amp;#34;/unikernel/mewz.elf&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.cmdline&amp;#34;=&amp;#34;hello&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.unikernelType&amp;#34;=&amp;#34;mewz&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.hypervisor&amp;#34;=&amp;#34;qemu&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can now build and package our mewz unikernel with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f Containerfile -t harbor.nbfc.io/nubificus/urunc/hello-mewz-qemu:test .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;running-wasm-over-mewz-unikernels-with-urunc&#34;&gt;Running WASM over Mewz unikernels with &lt;code&gt;urunc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Finally, we can run the Mewz unikernel we created as any other container:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -m 512m --rm -ti --runtime io.containerd.urunc.v2 harbor.nbfc.io/nubificus/urunc/hello-mewz-qemu:test
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;unikraft&#34;&gt;Unikraft&lt;/h2&gt;
&lt;p&gt;Unikraft is one of the most active unikernel projects. It allows the users to
create lightweight, highly customizable and efficient unikernel images. Unikraft
provides a POSIX-friendly environment, reducing the engineering effort of
porting existing applications and libraries. Furthermore, Unikraft aims for
binary compatibility with Linux, allowing the direct execution of Linux binaries
on top of Unikraft.&lt;/p&gt;
&lt;p&gt;However, in the case of WASM, the most interesting part in Unikraft is the
&lt;a href=&#34;https://github.com/unikraft/app-wamr/tree/stable&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;support of wamr&lt;/a&gt;. Using
&lt;a href=&#34;https://github.com/bytecodealliance/wasm-micro-runtime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wamr&lt;/a&gt; Unikraft is able
to execute WASM modules.&lt;/p&gt;
&lt;h3 id=&#34;unikraft-and-urunc&#34;&gt;Unikraft and &lt;code&gt;urunc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;In the case of Unikraft &lt;code&gt;urunc&lt;/code&gt; already has support and therefore no changes or
different branches are required. We can directly use the main branch.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ git clone https://github.com/nubificus/urunc.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ docker run --rm -ti -v &lt;span class=&#34;nv&#34;&gt;$PWD&lt;/span&gt;/urunc:/urunc -w /urunc golang:1.23 bash -c &lt;span class=&#34;s2&#34;&gt;&amp;#34;git config --global --add safe.directory /urunc &amp;amp;&amp;amp; make&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ sudo make -C urunc install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Please refer to &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc&lt;/a&gt; for more detailed
installation instructions.&lt;/p&gt;
&lt;h3 id=&#34;packaging-unikraft-unikernels-for-urunc&#34;&gt;Packaging Unikraft unikernels for &lt;code&gt;urunc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Similarly with Mewz, we will use &lt;a href=&#34;https://github.com/nubificus/pun&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pun&lt;/a&gt; to
package the Unikraft unikernel for &lt;code&gt;urunc&lt;/code&gt;. However, we need to build the
Unikraft unikernel by ourselves and then package it with &lt;code&gt;pun&lt;/code&gt;. We can build the
Unikraft unikernel with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/unikraft/app-wamr.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cd app-wamr
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir workdir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pushd workdir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/unikraft/unikraft.git -b RELEASE-0.15.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir libs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/unikraft/lib-lwip.git -b RELEASE-0.15.0 libs/lwip
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/unikraft/lib-musl.git -b RELEASE-0.15.0 libs/musl
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/unikraft/lib-wamr.git -b RELEASE-0.15.0 libs/wamr
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;popd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cp defconfigs/qemu-x86_64-initrd .config
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make olddefconfig
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If everything goes well, the unikernel binary should be placed in
&lt;code&gt;${PWD}/workdir/build/wamr_qemu-x86_64&lt;/code&gt;. In the case of Unikraft the WASM module
can be a typical WASM file and it should be placed in the initrd. In
the &lt;code&gt;app-wamr&lt;/code&gt; example, Unikraft already has a hello world WASM module, under
the &lt;code&gt;rootfs&lt;/code&gt; directory. Therefore, we will transform the contents of this
directory to a initrd. We can do that with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pushd rootfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;find -depth -print | tac | bsdcpio -o --format newc &amp;gt; ../rootfs.cpio
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;popd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The initrd file will be saved in the &lt;code&gt;rootfs.cpio&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;At last, we can package the Unikraft unikernel with &lt;code&gt;pun&lt;/code&gt;. For that purpose, we
will use the following &lt;code&gt;Containerfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#syntax=harbor.nbfc.io/nubificus/pun:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM scratch
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;COPY workdir/build/wamr_qemu-x86_64 /unikernel/wamr_qemu-x86_64
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;COPY rootfs.cpio /unikernel/initrd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL com.urunc.unikernel.binary=&amp;#34;/unikernel/wamr_qemu-x86_64&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.cmdline&amp;#34;=&amp;#34;/main.wasm&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.initrd&amp;#34;=&amp;#34;/unikernel/initrd&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.unikernelType&amp;#34;=&amp;#34;unikraft&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.hypervisor&amp;#34;=&amp;#34;qemu&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LABEL &amp;#34;com.urunc.unikernel.version&amp;#34;=&amp;#34;0.15.0&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can now build and package our Unikraft unikernel with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker build -f Containerfile -t nubificus/urunc/hello-wasm-unikraft-qemu:test .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;running-wasm-over-unikraft-unikernels-with-urunc&#34;&gt;Running WASM over Unikraft unikernels with &lt;code&gt;urunc&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;At last we can run the Unikraft unikernel we created as any other container:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run --rm -ti --runtime io.containerd.urunc.v2 harbor.nbfc.io/nubificus/urunc/hello-wasm-unikraft-qemu:test
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;summary-and-next-steps&#34;&gt;Summary and next steps&lt;/h2&gt;
&lt;p&gt;WASM offers unparalleled portability and near-native execution,
establishing itself as a key evolutionary technology in the cloud-native
ecosystem. However, despite its sandboxed execution model, security
vulnerabilities highlight the need for stronger isolation between workloads. In
this context, we explore the potential of using unikernels to isolate WASM
applications within VMs. By combining WASM’s portability with the
fast boot times and robust isolation offered by unikernels, we can create a
highly efficient and secure execution environment.&lt;/p&gt;
&lt;p&gt;Furthermore, the ability of &lt;code&gt;urunc&lt;/code&gt; to act as a container runtime for
unikernels, streamlines the deployment and management of WASM applications
running on unikernels. This enables us to deploy WASM applications with the same
ease as containers, while simultaneously ensuring strong isolation with minimal
overhead.&lt;/p&gt;
&lt;p&gt;In this post, we reviewed two unikernel frameworks that already support WASM.
Looking ahead, we plan to also provide more info regarding OSv as well.
Additionally, we identified the need for a unified approach to &lt;em&gt;building&lt;/em&gt; and
&lt;em&gt;packaging&lt;/em&gt; WASM unikernels as OCI images; for now, &lt;code&gt;pun&lt;/code&gt; only addresses the
latter. To address the former, we intend to complement &lt;code&gt;pun&lt;/code&gt; with a new tool
that will streamline the process of building and bundling all the binary
artifacts into a single application kernel, ready to be deployed.&lt;/p&gt;
&lt;p&gt;Stay tuned for more updates! In the meantime, please share your
comments/suggestions/findings on &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KubeCon &#43; CloudNativeCon Europe 2024: Unikernels in K8s - Performance and Isolation for Serverless Computing with Knative</title>
      <link>/event/kubeconeu2024/</link>
      <pubDate>Fri, 22 Mar 2024 13:00:00 +0000</pubDate>
      <guid>/event/kubeconeu2024/</guid>
      <description>&lt;h2 id=&#34;code--resources&#34;&gt;Code &amp;amp; Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/urunc-dev/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - Container Runtime Repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing Performance with Unikernels: Exploring Container Runtimes for Serverless Workloads with Knative Benchmarking</title>
      <link>/blog/knative-runtime-eval/</link>
      <pubDate>Fri, 24 Nov 2023 11:28:46 +0000</pubDate>
      <guid>/blog/knative-runtime-eval/</guid>
      <description>&lt;!-- [Knative](https://knative.dev/docs/concepts/#what-is-knative) --&gt;
&lt;p&gt;In our &lt;a href=&#34;/posts/knative-diverse-deployments/&#34;&gt;previous&lt;/a&gt; &lt;a href=&#34;/posts/urunc&#34;&gt;posts&lt;/a&gt;,
we walked through the process of configuring various low-level container
runtimes in Knative using the &lt;code&gt;RuntimeClass&lt;/code&gt; feature of K8s. We
&lt;a href=&#34;/posts/knative-diverse-deployments/#gvisor-deployment&#34;&gt;detailed&lt;/a&gt; the setup for
isolation mechanisms like
&lt;a href=&#34;/posts/knative-diverse-deployments/#gvisor-deployment&#34;&gt;gVisor&lt;/a&gt;, with a special
focus on Kata and its associated hypervisors, including &lt;a href=&#34;/posts/knative-diverse-deployments/#gvisor-deployment&#34;&gt;AWS
Firecracker&lt;/a&gt; and
&lt;a href=&#34;/posts/knative-diverse-deployments/#kata-qemu&#34;&gt;QEMU&lt;/a&gt;.  Additionally, we
&lt;a href=&#34;/posts/urunc&#34;&gt;delved&lt;/a&gt; into the capabilities of unikernels, showcasing the
power of &lt;code&gt;urunc&lt;/code&gt; in the serverless realm.&lt;/p&gt;
&lt;p&gt;Now, you might be wondering: What&amp;rsquo;s the real advantage beyond ensuring the
security isolation of workloads? Why choose one mechanism over another? And why
even dive into this conversation?&lt;/p&gt;
&lt;p&gt;This post aims to provide insights into these questions, shedding light on the
considerations and factors at play in the dynamic landscape of low-level
container runtimes for Knative workloads.&lt;/p&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;Despite  achieving security isolation through sandboxed container runtimes like
Kata-containers or gVisor, it is crucial to acknowledge that running
containerized workloads in a VM, isolated from the host kernel, can introduce
significant overhead to the final execution. In serverless architectures,
where the cost of a function is directly tied to deployment time, this
factor becomes a key consideration.&lt;/p&gt;
&lt;p&gt;Moreover, optimizing the use of hardware resources by activating them only when
necessary contributes to a &amp;lsquo;greener&amp;rsquo; cloud solution, reducing &lt;a href=&#34;https://github.com/Green-Software-Foundation/sci/blob/main/Software_Carbon_Intensity/Software_Carbon_Intensity_Specification.md#:~:text=be%20expanded%20to%3A-,SCI%20%3D%20%28O%20%2B%20M%29%20per%20R,-Operational%20emissions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Software Carbon
Intensity&lt;/a&gt;. Conventional practices, like booting an entire OS and unnecessary
libraries, can be counterproductive in terms of software stack complexity and
performance. To this end, we try to combine isolated execution of
user-workloads with optimal resource utilization and performance efficiency in
a serverless context.&lt;/p&gt;
&lt;p&gt;To validate the above hypothesis we present an initial, high-level performance
analysis of Knative using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;generic container runtimes (&lt;code&gt;runc&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;sandboxed container runtimes (&lt;code&gt;kata-containers&lt;/code&gt;, &lt;code&gt;gVisor&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;urunc&lt;/code&gt;, our own unikernel container runtime&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We base our measurements on our own
&lt;a href=&#34;https://github.com/nubificus/kperf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modified&lt;/a&gt; version of
&lt;a href=&#34;https://github.com/knative-extensions/kperf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;kperf&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Our primary focus revolved around examining function-spawning latency,
response time, and scalability. To achieve this, we developed
&lt;a href=&#34;https://github.com/nubificus/kperf-metrics-scripts/blob/main/get-metrics.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scripts&lt;/a&gt;  utilizing &lt;code&gt;kperf&lt;/code&gt; to specifically measure these aspects. Below, we showcase
two experiments conducted using &lt;code&gt;kperf&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The initial set of measurements pertain to &amp;ldquo;cold-start&amp;rdquo; latencies,
representing the duration required for a function to spawn and respond to a request.&lt;/li&gt;
&lt;li&gt;The second set, illustrates average latencies when concurrently spawning
multiple services.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By presenting these findings, our aim is to provide users with critical metrics
that aid in selecting the most efficient low-level container runtime,
optimizing their serverless workload performance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: &lt;code&gt;kperf&lt;/code&gt; development was stale for a while and Sep 15th the maintainers archived the
repo, focusing on a &lt;a href=&#34;https://github.com/knative/serving/tree/main/test/performance&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;different
approach&lt;/a&gt; for
benchmarking &lt;code&gt;Knative&lt;/code&gt;. We plan to gather metrics related to container runtimes
with this tool as well.&lt;/p&gt;
&lt;h3 id=&#34;architecture-overview&#34;&gt;Architecture overview&lt;/h3&gt;


















&lt;figure  id=&#34;figure-figure-1-knative-serving-stock-components-and-workflow&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/knative-runc.png#center&#34; alt=&#34;Figure 1: Knative Serving stock components and workflow.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 1: Knative Serving stock components and workflow.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Figure 1 depicts a typical &lt;code&gt;Knative&lt;/code&gt; setup on a k8s cluster. Boxes in light
blue show the &lt;code&gt;Knative&lt;/code&gt; components, while the ingress controller is assumed to
be provided by the infrastructure. Since &lt;code&gt;Knative&lt;/code&gt; function pods are
essentially containers, cloud vendors &lt;em&gt;refrain&lt;/em&gt; from serving multiple tenants on
shared hardware due the limitations this technology imposes on &lt;a href=&#34;https://thenewstack.io/interview-google-gvisor-and-the-challenge-of-securing-multitenant-containers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;isolating&lt;/a&gt; user
workloads. Consequently, these vendors opt to offer dedicated bare-metal or
virtualized infrastructure specifically for serverless tenants.&lt;/p&gt;
&lt;p&gt;A solution to the issue above, could be to sandbox the user workload (the
Serverless Function) in an enclave that protects the host (and the rest of the
tenants) from potentially malicious code. Figure 2 shows an alternative setup
to the default, where the function pods are being spawned using sandboxed
container runtimes such as kata-containers (left) and gVisor (right).&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-2-knative-serving-with-sandboxed-container-runtimes&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/knative-sandboxed.png#center&#34; alt=&#34;Figure 2: Knative Serving with sandboxed container runtimes.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 2: Knative Serving with sandboxed container runtimes.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;This mechanism has merits and shortcomings:&lt;/p&gt;
&lt;p&gt;cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the sandbox spawn is on the critical path (slower cold boot times)&lt;/li&gt;
&lt;li&gt;the code executing in the user-container runs virtualized (no straightforward
access to hardware accelerators)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the code executing in the user-container runs virtualized: it is much harder
for malicious user code to escape to the host and/or access sensitive data
from the system or other co-located tenants.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;user-workloads&#34;&gt;User workloads&lt;/h4&gt;
&lt;p&gt;Another point of discussion is the type of workloads in a typical serverless
setup. What do users run, or better, how complicated is the code that users run
in a common serverless application?&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2451116.2451167&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unikernels&lt;/a&gt;
have come a long way since their inception several years ago, where
they showed great potential (e.g. millisecond boot times, ultra low OS memory
consumption) but were difficult to use, hard to debug or limited in
functionality. Today, with the advent of approaches to run unmodified Linux
binaries as unikernels, or automate the building process they seem ready for
prime time.&lt;/p&gt;
&lt;p&gt;In an effort to combine the isolation characteristics of virtualization /
sandboxed container runtimes and the lightweight nature of unikernels, we couple
unikernels and containers with &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt;
and deploy Knative functions on top of that, bringing the system management
overhead for a secure, isolated, and efficient serverless deployment to the
bare minimum.&lt;/p&gt;
&lt;p&gt;To validate our assumptions, we measure end-to-end service latencies across various
container runtimes, including: &lt;code&gt;generic&lt;/code&gt;, &lt;code&gt;gvisor&lt;/code&gt;, &lt;code&gt;kata-qemu&lt;/code&gt;, &lt;code&gt;kata-fc&lt;/code&gt;, &lt;code&gt;kata-rs&lt;/code&gt;, &lt;code&gt;kata-clh&lt;/code&gt;,
and &lt;code&gt;urunc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We assume the bare minimum in terms of application (user-container), a simple HTTP reply program
written in
&lt;a href=&#34;https://github.com/nubificus/helloworld-knative/blob/main/hello.go&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;go&lt;/a&gt; for
the generic and sandboxed functions and in
&lt;a href=&#34;https://github.com/nubificus/app-httpreply/tree/nbfc-knative&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;C&lt;/a&gt; for the
unikernel function.&lt;/p&gt;
&lt;p&gt;The individual steps that comprise the service latency measured are shown below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kperf&lt;/code&gt; issues the request that reaches the ingress controller&lt;/li&gt;
&lt;li&gt;the request traverses the networking stack of k8s and reaches the &lt;code&gt;activator&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;activator&lt;/code&gt; triggers the deployment of a function pod&lt;/li&gt;
&lt;li&gt;upon the creation of the function pod, the request reaches &lt;code&gt;queue-proxy&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;queue-proxy&lt;/code&gt; forwards the request to the &lt;code&gt;user-container&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;user-container&lt;/code&gt; replies to &lt;code&gt;kperf&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure 4 visualizes these steps in a sequence diagram, presenting which
components interact with each other, as well as the time spent at each part for
the flow.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-4-end-to-end-request-servicing-on-knative-cold-instantiation&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/knative-workflow.png#center&#34; alt=&#34;Figure 4: End-to-end request servicing on Knative (cold instantiation).&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 4: End-to-end request servicing on Knative (cold instantiation).
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;In what follows, we briefly describe the hardware and software components that
comprise our experimental setup, and present the measurements we captured.&lt;/p&gt;
&lt;h3 id=&#34;experimental-testbed&#34;&gt;Experimental testbed&lt;/h3&gt;
&lt;p&gt;For our measurements, we use a bare metal server from
&lt;a href=&#34;https://www.hetzner.com/dedicated-rootserver/ax161/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hetzner&lt;/a&gt; with 32 physical
cores and 128GB RAM. Detailed specifications are shown in the table below:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;CPU&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Memory&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Storage&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Network&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;OS&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;AMD EPYC 7502P &amp;ldquo;Rome&amp;rdquo; (32 Cores) Zen2&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;4 x 32 GB DDR4 ECC&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;960 GB NVMe SSD Datacenter Edition&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Internal (single server setup)&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Ubuntu 22.04.3 LTS (jammy)&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The software stack we use for our tests is focused around the requirements for
a generic k8s plus Knative &lt;a href=&#34;https://knative.dev/docs/install/yaml-install/serving/install-serving-with-yaml/#prerequisites&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;setup&lt;/a&gt;, along with the sandboxed container runtimes and &lt;code&gt;urunc&lt;/code&gt;.
Detailed components and versions are shown in the table below:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Linux&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;runc&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;containerd&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;nerdctl&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;kubelet&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;calico&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;kata-containers&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;kperf&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Knative serving&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v5.15.0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v1.1.9&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v1.7.5&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v0.20.0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v1.28.2&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v3.26.0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v3.2.0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v20231115-78dabcb&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;v1.12.0&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To enhance kperf, we initiated a tailored development process by forking and constructing our
unique iteration. Among the fundamental modifications crucial for efficient result collection was
the &lt;a href=&#34;https://github.com/knative-extensions/kperf/commit/191436bfa78e4fedfb7c020e89d8373b099ef917&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;redirection&lt;/a&gt;
of &lt;code&gt;GET&lt;/code&gt; requests to the ingress controller with the appropriate headers
and the implementation of &lt;a href=&#34;https://github.com/knative-extensions/kperf/commit/fca4a218acd166ff4d10cd2c65e9eacd8257a1c4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;timeouts&lt;/a&gt; inserted specifically for clients.
This was imperative to alleviate the issue of non-responsive services caused by
hardware constraints, notably the burden of spawning an excessive number of services.&lt;/p&gt;
&lt;p&gt;With these modifications implemented, we effectively utilized kperf&amp;rsquo;s &lt;a href=&#34;https://github.com/knative-extensions/kperf/blob/main/docs/examples.md#scale-from-zero-and-measure-knative-service-latency&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;scale&lt;/code&gt;&lt;/a&gt;
command to gather latency statistics for both single-service function instances
and multiple services spawned simultaneously.
Moreover, the incorporation of a helper
&lt;a href=&#34;https://github.com/nubificus/kperf-metrics-scripts/blob/main/get-metrics.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;script&lt;/a&gt;
facilitated an automated
process for retrieving this data and dynamically adjusting the low-level
runtime of workloads as well as the number of concurrently
spawned services.&lt;/p&gt;
&lt;p&gt;Furthermore, we undertook another aspect of our work aimed at enhancing the accuracy of retrieved metrics.
This involved disabling the CPU frequency scaler, responsible for dynamically modifying the CPU cores&amp;rsquo; frequency.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cpupower frequency-set --governor performance
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By disable frequency scaling, we are essentially ensuring that the CPU operates
at a constant frequency leading to more stable and accurate metric retrieval.&lt;/p&gt;
&lt;p&gt;At the same time, limiting the CPU cores&amp;rsquo; &lt;code&gt;turbo&lt;/code&gt; feature, allows us to capture reproducible metrics.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;echo &amp;#34;0&amp;#34; | sudo tee /sys/devices/system/cpu/cpufreq/boost
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h3&gt;
&lt;p&gt;We plot our findings and present an initial analysis of Knative performance
over the various container runtimes we consider for our tests.&lt;/p&gt;
&lt;h4 id=&#34;service-response-latency-single-instance&#34;&gt;Service Response Latency (single instance)&lt;/h4&gt;
&lt;p&gt;We first test the total time needed for a single request to reach a defined,
but not provisioned, &lt;code&gt;Knative&lt;/code&gt; service. Essentially, this metric represents how
much time the user will wait for a service when they first access it. Usually,
the dominating part of this time is the &lt;em&gt;cold-boot&lt;/em&gt; time of the function.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Parameter name&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Value&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Metric&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;timeout&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;3&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Duration to wait for Knative Service to be ready&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;time-interval&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;90&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;The time interval of each scale up&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;iterations&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;30&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;-&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;nr of consecutive runs of the same test&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;scale-client-timeout&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;100&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;time to give up on the operation (non-responsive service)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;stable-window&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;25&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&amp;ldquo;&lt;a href=&#34;https://knative.dev/docs/serving/autoscaling/scale-bounds/#stable-window&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;time window&lt;/a&gt; over which metrics are averaged to provide the input for scaling decisions&amp;rdquo;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;kperf&lt;/code&gt; reports this metric as &lt;em&gt;Service Response Latency&lt;/em&gt;. The &lt;a href=&#34;https://github.com/nubificus/kperf#:~:text=default%20%22/home/ubuntu/.config/kperf/config.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;parameters&lt;/a&gt; we
used for setting up &lt;code&gt;kperf&lt;/code&gt; are shown in the table above.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Service Latency&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Average&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Minimum&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Maximum&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;generic&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;1.20&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;0.92&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;gvisor&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;2.21&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2.15&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;2.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;kata-qemu&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;2.21&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2.10&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;2.23&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;kata-fc&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;2.21&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2.21&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;2.22&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;urunc&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;strong&gt;1.21&lt;/strong&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1.19&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1.23&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The table above, summarizes the absolute service latency for the various
container runtimes in our test. We plot these results in Figure 4.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-4-service-response-latency-as-a-function-of-the-various-container-runtimes&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/svc_latency.png#center&#34; alt=&#34;Figure 4: Service Response Latency as a function of the various container runtimes.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 4: Service Response Latency as a function of the various container runtimes.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Figure 4 depicts the service response latency for the sandboxed container
runtimes and &lt;code&gt;urunc&lt;/code&gt;. The horizontal lines show the average response latency,
while the vertical lines depict the minimum (lower) and maximum (higher)
response latency captured during our test.&lt;/p&gt;
&lt;p&gt;An expected observation in Figure 4 is that the sandboxed container runtimes
require 2-2.5 seconds for servicing a request. The parameters for
each one vary depending on the sandbox technology used, but on average a request will
be served in approximately 2.21 seconds.&lt;/p&gt;
&lt;p&gt;Moreover, using the generic container runtime, we see that a request is being
served in approximately 1.20 seconds.&lt;/p&gt;
&lt;p&gt;Additionally, Figure 4 shows that the behavior of &lt;code&gt;urunc&lt;/code&gt; is on par with the generic
container runtime (&lt;code&gt;runc&lt;/code&gt;). The performance of our early version of &lt;code&gt;urunc&lt;/code&gt; is
comparable to &lt;code&gt;runc&lt;/code&gt; (~1.21s on average vs 1.20s for &lt;code&gt;runc&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Finally, the maximum service request latency for &lt;code&gt;runc&lt;/code&gt; and &lt;code&gt;urunc&lt;/code&gt; do not
exceed 5% of the total latency.&lt;/p&gt;
&lt;p&gt;Figure 5 plots the 99th percentile of Service latency for the various runtimes,
proving that &lt;code&gt;urunc&lt;/code&gt; can sustain low latency even for slower requests.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-5-service-response-latency-for-the-99th-percentile-as-a-function-of-the-various-container-runtimes&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/svc_latency_99th.png#center&#34; alt=&#34;Figure 5: Service Response Latency for the 99th percentile as a function of the various container runtimes.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 5: Service Response Latency for the 99th percentile as a function of the various container runtimes.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The takeaway message from Figures 4 and 5 is that unikernels can achieve the
same or (yet to be proven) better performance than generic containers when it
comes to serverless functions!&lt;/p&gt;
&lt;h4 id=&#34;concurrent-servicing-multiple-instances&#34;&gt;Concurrent servicing (multiple instances)&lt;/h4&gt;
&lt;p&gt;In this test we want to assess the footprint and responsiveness of a &lt;code&gt;Knative&lt;/code&gt;
service by scaling to a large number of instances.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Parameter name&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Value&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Metric&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;timeout&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;3&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;Duration to wait for Knative Service to be ready&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;time-interval&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;95&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;The time interval of each scale up&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;iterations&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;15&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;-&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;nr of consecutive runs of the same test&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;scale-client-timeout&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;120&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;time to give up on the operation (non-responsive service)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;code&gt;stable-window&lt;/code&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;300&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;sec&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&amp;ldquo;&lt;a href=&#34;https://knative.dev/docs/serving/autoscaling/scale-bounds/#stable-window&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;time window&lt;/a&gt; over which metrics are averaged to provide the input for scaling decisions&amp;rdquo;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The parameters we used for setting up &lt;code&gt;kperf&lt;/code&gt; can be found in the table above.&lt;/p&gt;
&lt;p&gt;One distinction in the parameters for the single-instance scale metrics involves the extension of the stable-window duration.
This extension ensures an extended lifespan for functions/pods, thereby guaranteeing that the required number of services remains
concurrently operational.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-5-service-response-latency-for-various-container-runtimes-when-servicing-multiple-parallel-requests&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/conc_latency.png#center&#34; alt=&#34;Figure 5: Service Response Latency for various container runtimes when servicing multiple parallel requests.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 5: Service Response Latency for various container runtimes when servicing multiple parallel requests.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Figure 5 presents the average service response latency (sec) for each container
runtime as a function of the number of concurrent instances of the service. From this figure, some interesting conclusions can be drawn:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;generic&lt;/code&gt;, &lt;code&gt;gvisor&lt;/code&gt;, and &lt;code&gt;urunc&lt;/code&gt; exhibit similar behavior when increasing the
number of instances&lt;/li&gt;
&lt;li&gt;&lt;code&gt;urunc&lt;/code&gt; and &lt;code&gt;generic&lt;/code&gt; appear identical in terms of response latency even when
scaling to 250 services.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gvisor&lt;/code&gt; exhibits approximately an average of +1.5sec latency compared to
&lt;code&gt;urunc&lt;/code&gt;. This accounts for 2x the latency for instances up to 125.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kata-*&lt;/code&gt;&amp;rsquo;s overhead ranges from 2x to 3x latency compared to &lt;code&gt;urunc&lt;/code&gt; up to
125 instances and approximately 1.5x for more instances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although the target number of services is defined, some of the instances did
not manage to produce a response after 125. Figure 6 summarizes
how many actual instances responded in our test for the various runtimes.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-6-number-of-instances-spawned-for-various-container-runtimes-as-a-function-of-the-target-services-requested&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/scale_instances_spawned.png#center&#34; alt=&#34;Figure 6: Number of Instances spawned for various container runtimes as a function of the target services requested.&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 6: Number of Instances spawned for various container runtimes as a function of the target services requested.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;h4 id=&#34;pushing-the-scaling-limits&#34;&gt;Pushing the scaling limits&lt;/h4&gt;
&lt;p&gt;To explore the maximum amount of services supported on the testbed hardware, we increase the number of services to 500 for &lt;code&gt;urunc&lt;/code&gt; and capture:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the number of actual services spawned&lt;/li&gt;
&lt;li&gt;the service response latency in this context.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We compare these results with the generic container runtime.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-7-number-of-instances-spawned-target-500-for-various-container-runtimes-higher-is-better&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/scale_instances.png#center&#34; alt=&#34;Figure 7: Number of Instances spawned (target 500) for various container runtimes (higher is better).&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 7: Number of Instances spawned (target 500) for various container runtimes (higher is better).
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Figure 7 plots the number of spawned instances for the generic container
runtime and &lt;code&gt;urunc&lt;/code&gt;  with a target of 500. The achievable number for each
container runtime is shown in the plot. We can see that &lt;code&gt;urunc&lt;/code&gt; is able to
spawn as much instances as &lt;code&gt;runc&lt;/code&gt;, enabling the sandboxing of user code without
imposing any additional overhead in terms of memory / CPU footprint.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-7-service-response-latency-for-multiple-concurrent-instances-500-for-various-container-runtimes-lower-is-better&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/knative/scale_instances_svc.png#center&#34; alt=&#34;Figure 7: Service Response Latency for multiple concurrent instances (500) for various container runtimes (lower is better).&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 7: Service Response Latency for multiple concurrent instances (500) for various container runtimes (lower is better).
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;To validate that the services are responsive and to assess the latency imposed
by so many services running at the same time, we plot the Average response
latency for these services. Figure 7 shows that &lt;code&gt;urunc&lt;/code&gt; is able to sustain low
response latency compared to the generic container runtime, even with ~450
instances running.&lt;/p&gt;
&lt;h4 id=&#34;conclusions-and-next-steps&#34;&gt;Conclusions and next steps&lt;/h4&gt;
&lt;p&gt;In this post, we went through an initial evaluation of container runtimes that
sandbox the user code in a serverless environment such as Knative. We presented
the rationale of sandboxing serverless functions, following up from our
previous posts regarding &lt;a href=&#34;/posts/knative-diverse-deployments&#34;&gt;alternative container runtimes&lt;/a&gt; for
Knative and &lt;a href=&#34;/posts/urunc&#34;&gt;&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt;, our own container runtime for unikernels.&lt;/p&gt;
&lt;p&gt;Isolating the user code from the platform allows cloud vendors to better
utilize their infrastructure and enables users to share infrastructure without
compromising their isolation requirements. Especially in the context of
serverless computing, unikernels seem like a great fit, combining the isolation
principles of Virtual Machines, without the overhead and management burden of
generic, full virtualization stacks.&lt;/p&gt;
&lt;p&gt;There are still a few ways to go for the wider adoption of unikernels, but
still, we are working towards this direction and, hopefully, we get to see
unikernels in production soon!&lt;/p&gt;
&lt;p&gt;Our plan is to continue de-mystifying quirks and issues with serverless
platforms and focus on evaluating our approach on devices with lower compute
capabilities, as well as add hardware acceleration to the mix!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>urunc: Introducing a unikernel container runtime</title>
      <link>/blog/urunc/</link>
      <pubDate>Tue, 14 Nov 2023 15:22:12 +0000</pubDate>
      <guid>/blog/urunc/</guid>
      <description>

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-logo.png#floatleft&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;18%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;This post is about &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt;, a tool that
we build to treat unikernels as containers and properly introduce unikernels to
the cloud-native world! Essentially, &lt;code&gt;urunc&lt;/code&gt; is a container runtime able to
spawn unikernels that reside in container images. Before digging into the gory
details, let us walk through some required concepts: unikernels, containers,
and container runtimes.&lt;/p&gt;
&lt;h2 id=&#34;what-are-unikernels&#34;&gt;What are unikernels&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/2451116.2451167&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unikernels&lt;/a&gt; is a technology that was introduced in 2013 and has been quietly evolving for some years now. They can be seen as highly specialized, lightweight operating systems. Unlike traditional general purpose operating systems, unikernels are tailored for the singular purpose of running a specific application with efficiency, eliminating unnecessary overhead and minimizing footprint. A unikernel contains all the essential components needed for running a particular application, including the application code and the necessary portions of the operating system code. Additionally, everything that is not required for running the app is stripped out of the unikernel. That results in a self-contained, portable and minimal unit of software that can be run anywhere with virtually no overhead and significantly decreased attack surface.&lt;/p&gt;
&lt;h2 id=&#34;unikernels-use-cases&#34;&gt;Unikernels use cases&lt;/h2&gt;
&lt;p&gt;Due to their inherent design simplicity, low footprint and near-instant spawn
times, unikernels seem suitable for a number of interesting use-cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Serverless functions&lt;/strong&gt;:
With ultra-fast boot times and efficient execution unikernels are a great fit for the dynamic environment of serverless functions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SaaS/microservices&lt;/strong&gt;:
In SaaS and microservices environments, unikernels provide a tailored solution by isolating individual applications, minimizing interference, and enhancing security in multi-tenant scenarios.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Edge deployments for resource-constrained devices&lt;/strong&gt;:
Due to their minimal footprint, unikernels can shine in edge computing by efficiently utilizing limited resources, ensuring optimal performance for deployment in edge devices.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;comparing-unikernels-and-containers&#34;&gt;Comparing unikernels and containers&lt;/h2&gt;
&lt;p&gt;How do unikernels compare to containers, the current standard of software delivery and execution? In our experience, there are some benefits and some drawbacks when it comes to adopting unikernels. We present the basic criteria and some comments on each technology below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;:
While containers are known for their lightweight nature, unikernels take this to the next level, offering an even more streamlined and specialized environment. By eliminating non-essential components, unikernels minimize their footprint to an extent beyond what traditional containers achieve.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Portable&lt;/strong&gt;:
Both containers and unikernels maintain a similar level of portability, allowing applications to run consistently across various environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficient Resource Consumption&lt;/strong&gt;:
Efficiency in resource consumption is a shared strength between containers and unikernels. Both excel in optimizing resource usage, but unikernels, with their minimalistic design, stand out in resource-constrained environments, ensuring optimal performance with minimal overhead.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalable&lt;/strong&gt;:
The scalability factor remains comparable between containers and unikernels. Both can be scaled horizontally to meet increased demand, providing a responsive and adaptable infrastructure for dynamic workloads.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Isolated&lt;/strong&gt;:
Containers provide a certain level of isolation using mechanisms like cgroups and namespaces. However, unikernels benefit from hardware isolation, offering the same security as traditional VMs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy to Use&lt;/strong&gt;:
Containers boast a wide and well-defined ecosystem of tools designed to package, distribute, execute and orchestrate application. Unikernels, while powerful, are not as intuitive or as easy to use for those accustomed to the simplicity of container technologies. They require a more specialized understanding of application architecture and deployment. Furthermore, there are some missing tools required to elevate unikernels to the status of a first-class citizen in the cloud-native landscape.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-missing&#34;&gt;What is missing?&lt;/h2&gt;
&lt;p&gt;The technology behind unikernels is a good candidate for cloud deployments,
especially in the case of Microservices and FaaS. However, an important
component is missing; the tool that will spawn unikernels and manage their
lifecycle. At the same time, industry standards, such as the Open Container
Initiative create specific requirements for such a tool. &lt;code&gt;urunc&lt;/code&gt; aspires to
fill this gap, enabling the use of unikernels in cloud-native environments as
simply as containers.&lt;/p&gt;
&lt;p&gt;Unikernels are not a drop-in replacement for containers. First off, there&amp;rsquo;s no simple and user-friendly way to build unikernels for specific applications (more on this coming soon). Then, there is no way to package and distribute unikernels like OCI images. Additionally, there&amp;rsquo;s no tooling to run unikernels in a way that is compatible with OCI standards.&lt;/p&gt;
&lt;p&gt;The closest tools we have for deploying unikernels are the ones made for VMs: typical sandboxed container runtimes such as &lt;a href=&#34;https://github.com/kata-containers/kata-containers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;kata-containers&lt;/code&gt;&lt;/a&gt;, or VM management tools like &lt;a href=&#34;https://github.com/libvirt/libvirt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;libvirt&lt;/code&gt;&lt;/a&gt;. However, since unikernels are not typical VMs (there&amp;rsquo;s no operating system, no agent to communicate with the container runtime to setup a container in the sandbox etc.), they fall short of being real substitute for sandboxed containers.&lt;/p&gt;
&lt;p&gt;To this end, after experimenting with the tools available (essentially &lt;code&gt;kata-containers&lt;/code&gt;), to build a simple unikernel container runtime based on &lt;a href=&#34;https://github.com/nubificus/kata-containers/tree/feat_kata_urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;existing functionality&lt;/a&gt;, we felt that the time has come to take a step back, follow a much simpler design and build &lt;em&gt;the&lt;/em&gt; unikernel container runtime: &lt;code&gt;urunc&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;enter-urunc&#34;&gt;Enter urunc&lt;/h2&gt;
&lt;p&gt;Generic container runtimes (such as &lt;a href=&#34;https://github.com/opencontainers/runc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;runc&lt;/code&gt;&lt;/a&gt; manage the systems stack where applications are spawned.
A unique feature of unikernels is that they are self-contained: an application runs along with its library and OS dependencies as a single address-space VM image, combining the systems stack and application. Leveraging this feature, &lt;code&gt;urunc&lt;/code&gt; maps each application/unikernel to a single container, thus, enabling direct management of applications from the container runtime itself.&lt;/p&gt;
&lt;p&gt;There is no notion of a VM sandbox, while at the same time, virtualization extensions ensure proper isolation between user-code (the unikernel) and the rest of the system. This is also inherent from the design of unikernels, which are, essentially, VMs.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-1-abstract-design-of-urunc&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-high-level.png#center&#34; alt=&#34;Figure 1: Abstract design of `urunc`&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 1: Abstract design of &lt;code&gt;urunc&lt;/code&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The design of &lt;code&gt;urunc&lt;/code&gt; separates each individual component into go packages that
can be exported (and exposed) to other components if needed. Moreover, &lt;code&gt;urunc&lt;/code&gt;
follows the
&lt;a href=&#34;https://www.ianlewis.org/en/container-runtimes-part-2-anatomy-low-level-contai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;standard&lt;/a&gt;
container runtime design; mainly for maintainability, but for easier debugging
and extensibility as well.&lt;/p&gt;
&lt;h3 id=&#34;oci-artifacts&#34;&gt;OCI artifacts&lt;/h3&gt;
&lt;p&gt;Unikernel images for &lt;code&gt;urunc&lt;/code&gt; adhere to the Open Container Initiative (OCI) standards, making them easily shareable and deployable across compatible platforms. To facilitate the building and packaging of container images for &lt;code&gt;urunc&lt;/code&gt;, we build &lt;a href=&#34;https://github.com/nubificus/bima&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;bima&lt;/code&gt;&lt;/a&gt;, a simple tool that adds unikernel binaries to container image layers, and packages the artifacts as OCI-compatible images with metadata. An example of a &lt;code&gt;Containerfile&lt;/code&gt; we use to package an nginx unikernel, built with the &lt;a href=&#34;https://github.com/rumprun/rumprun&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rumprun&lt;/a&gt; toolstack, over &lt;a href=&#34;https://github.com/solo5/solo5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;solo5&lt;/a&gt;, along with its accompanying files is shown below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Dockerfile&#34; data-lang=&#34;Dockerfile&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# the FROM instruction will not be parsed&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; scratch&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; nginx.hvt /unikernel/nginx.hvt&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; data /&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LABEL&lt;/span&gt; com.urunc.unikernel.binary&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/unikernel/nginx.hvt&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LABEL&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;com.urunc.unikernel.cmdline&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LABEL&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;com.urunc.unikernel.unikernelType&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;rumprun&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LABEL&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;com.urunc.unikernel.hypervisor&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;hvt&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;container-unikernel-spawning&#34;&gt;Container (Unikernel) spawning&lt;/h3&gt;
&lt;p&gt;Leveraging the power of underlying hypervisors, &lt;code&gt;urunc&lt;/code&gt; spawns unikernel virtual machines (VMs), facilitating the deployment process. Furthermore, it is designed to be extensible making really easy to support multiple hypervisors and unikernel types.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-2-urunc-execution-flow&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-flow.png#center&#34; alt=&#34;Figure 2: `urunc` execution flow&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 2: &lt;code&gt;urunc&lt;/code&gt; execution flow
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The high-level execution flow is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;containerd&lt;/code&gt; pulls the image from a container registry, unpacks it and
prepares the storage backend with the container rootfs (eg. a block device
for the &lt;code&gt;devmapper&lt;/code&gt; snapshotter).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;containerd&lt;/code&gt; invokes &lt;code&gt;urunc&lt;/code&gt; with the bundle &amp;amp; storage backend&lt;/li&gt;
&lt;li&gt;&lt;code&gt;urunc&lt;/code&gt; parses the annotations in the bundle and extracts the unikernel binary&lt;/li&gt;
&lt;li&gt;&lt;code&gt;urunc&lt;/code&gt; constructs the apropriate command-line parameters for the respective hypervisor and spawns the unikernel&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regarding network handling, &lt;code&gt;urunc&lt;/code&gt; creates a new &lt;code&gt;tap&lt;/code&gt; device inside the container netns (&lt;code&gt;tap0_urunc&lt;/code&gt;). &lt;code&gt;urunc&lt;/code&gt; maps all incoming traffic from the CNI &lt;code&gt;veth&lt;/code&gt; endpoint to the &lt;code&gt;tap&lt;/code&gt; interface and all outgoing traffic to the &lt;code&gt;veth&lt;/code&gt; endpoint. This process is shown in Figure 3.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-3-urunc-network-flow&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-network.png#center&#34; alt=&#34;Figure 3: `urunc` network flow&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 3: &lt;code&gt;urunc&lt;/code&gt; network flow
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Regarding storage, &lt;code&gt;urunc&lt;/code&gt; extracts the unikernel binary from the container image. Then, it extracts any additional files present in the container image rootfs, to be used as additional storage for the unikernel. &lt;code&gt;urunc&lt;/code&gt; prepares and attaches the storage backend to the unikernel via the relevant command line directives of each hypervisor and unikernel type. This process is shown in Figure 4.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-4-urunc-storage-handling&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-storage.png#center&#34; alt=&#34;Figure 4: `urunc` storage handling&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;80%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 4: &lt;code&gt;urunc&lt;/code&gt; storage handling
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&#34;k8s-integration&#34;&gt;k8s integration&lt;/h3&gt;
&lt;p&gt;One of our initial goals was to bring unikernels to the cloud-native world. With &lt;code&gt;urunc&lt;/code&gt; we are finally able to spawn unikernels in k8s, without the burden of &lt;code&gt;libvirt&lt;/code&gt; and its complicated integration with container runtimes and tools. &lt;code&gt;urunc&lt;/code&gt;&amp;rsquo;s integration with k8s is as smooth as any other Container Runtime Interface (CRI)-compatible container runtime.&lt;/p&gt;
&lt;p&gt;We achieved this through a minor workaround: Kubernetes primarily focuses on pods as its core abstraction, housing containers within them. To ensure resource sharing among containers within the same pod, Kubernetes initializes a container that remains idle (sleeping) to sustain active namespaces for the other containers within the pod to connect to.&lt;/p&gt;
&lt;p&gt;So we had two options: (a) either include the handling of a generic container in &lt;code&gt;urunc&lt;/code&gt; or (b) delegate this handling to &lt;code&gt;runc&lt;/code&gt;.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-5-urunc-in-k8s&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-k8s.png#center&#34; alt=&#34;Figure 5: `urunc` in k8s&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;50%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 5: &lt;code&gt;urunc&lt;/code&gt; in k8s
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;We chose option (b). Figure 5 visualizes the process to spawn a unikernel container in k8s using &lt;code&gt;urunc&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;urunc-in-action&#34;&gt;urunc in action&lt;/h3&gt;
&lt;p&gt;Below you can see how we can deploy a &lt;a href=&#34;https://redis.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;redis&lt;/a&gt; key-value store
server as a rumprun unikernel on &lt;a href=&#34;https://github.com/solo5/solo5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;solo5&lt;/a&gt; using
&lt;code&gt;urunc&lt;/code&gt; and &lt;code&gt;nerdctl&lt;/code&gt;.&lt;/p&gt;


















&lt;figure  id=&#34;figure-figure-6-a-redis-rumprun-unikernel-over-solo5-spawned-with-nerdctl-and-urunc&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;/images/urunc/urunc-nerdctl-example.gif#center&#34; alt=&#34;Figure 6: A redis rumprun unikernel over solo5 spawned with `nerdctl` and `urunc` &#34; loading=&#34;lazy&#34; data-zoomable width=&#34;100%&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 6: A redis rumprun unikernel over solo5 spawned with &lt;code&gt;nerdctl&lt;/code&gt; and &lt;code&gt;urunc&lt;/code&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;urunc&lt;/code&gt;&lt;/a&gt; is open-source software, licensed
under &lt;a href=&#34;https://github.com/nubificus/urunc/blob/main/LICENSE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache-2.0&lt;/a&gt;. &lt;a href=&#34;https://github.com/nubificus/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Get
the code&lt;/a&gt; and start hacking!&lt;/p&gt;
&lt;p&gt;Stay tuned for a hands-on post on how to run your own unikernel using &lt;code&gt;urunc&lt;/code&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OSS 2023: URUNC - A Unikernel Container Runtime</title>
      <link>/event/oss2023/</link>
      <pubDate>Wed, 20 Sep 2023 12:40:00 +0000</pubDate>
      <guid>/event/oss2023/</guid>
      <description>&lt;h2 id=&#34;code--resources&#34;&gt;Code &amp;amp; Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/urunc-dev/urunc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;urunc - Container Runtime Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nubificus/bima&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bima - Unikernel Containerization Tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
