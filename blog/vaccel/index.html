<!doctype html><!-- This site was created with Hugo Blox. https://hugoblox.com --><!-- Last Published: February 21, 2026 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.216805a2797aee3439f2656fb7a5e910.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-KSC25ZE341"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-KSC25ZE341",{anonymize_ip:!0}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><meta name=author content="Anastassios Nanos"><meta name=description content="The debate on how to deploy applications, monoliths or micro services, is in
full swing. Part of this discussion relates to how the new paradigm
incorporates support for accessing accelerators, e.g. GPUs, FPGAs. That kind
of support has been made available to traditional programming models the last
couple of decades and its tooling has evolved to be stable and standardized."><link rel=alternate hreflang=en-us href=/blog/vaccel/><link rel=canonical href=/blog/vaccel/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu_997e0522978c46c6.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu_409bdbda4e241619.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@nubificus"><meta property="twitter:creator" content="@nubificus"><meta property="twitter:image" content="/media/logo_hu_866fdf07312224c.png"><meta property="og:type" content="website"><meta property="og:site_name" content="Nubificus"><meta property="og:url" content="/blog/vaccel/"><meta property="og:title" content="Hardware acceleration in the Age of Functions | Nubificus"><meta property="og:description" content="The debate on how to deploy applications, monoliths or micro services, is in
full swing. Part of this discussion relates to how the new paradigm
incorporates support for accessing accelerators, e.g. GPUs, FPGAs. That kind
of support has been made available to traditional programming models the last
couple of decades and its tooling has evolved to be stable and standardized."><meta property="og:image" content="/media/logo_hu_866fdf07312224c.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2020-06-01T20:29:17+00:00"><meta property="article:modified_time" content="2020-06-01T20:29:17+00:00"><script src=https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin=anonymous><script>window.addEventListener("load",function(){window.cookieconsent.initialise({palette:{popup:{background:"#1565c0",text:"rgb(255, 255, 255)"},button:{background:"rgb(255, 255, 255)",text:"#1565c0"}},theme:"classic",content:{message:"This website uses cookies to ensure you get the best experience on our website.",dismiss:"Got it!",link:"Learn more",href:"https://www.cookiesandyou.com"}})})</script><title>Hardware acceleration in the Age of Functions | Nubificus</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=7daa87280e6e200fa7e766c6a279afeb><script src=/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js></script><div class="page-header header--fixed"><style>.navbar-logo img{max-height:45px;width:auto;display:block}.navbar-logo .logo-dark{display:none}body.colorscheme-dark .navbar-logo .logo-light,body.dark .navbar-logo .logo-light{display:none}body.colorscheme-dark .navbar-logo .logo-dark,body.dark .navbar-logo .logo-dark{display:block}.navbar-logo.logo-nubis,.navbar-logo.logo-nubificus{display:none}</style><script>document.addEventListener("DOMContentLoaded",function(){var e=window.location.hostname,t=e==="nubis-pc.eu"||e==="www.nubis-pc.eu",n=t?"logo-nubis":"logo-nubificus";document.querySelectorAll(".navbar-logo."+n).forEach(function(e){e.style.display="flex"}),document.querySelectorAll("[data-brand]").forEach(function(e){var n=e.getAttribute("data-brand");t?e.textContent=n==="primary"?"Nubis":"Nubificus":e.textContent=n==="primary"?"Nubificus":"Nubis"})})</script><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><div class="navbar-logo logo-nubificus"><img class=logo-light src=/media/logo-nubificus_hu_7be4fa6b19286a64.png alt=Nubificus>
<img class=logo-dark src=/media/logo-nubificus-dark_hu_bd80a6d6121ee2ff.png alt=Nubificus></div><div class="navbar-logo logo-nubis"><img class=logo-light src=/media/logo-nubis.png alt="Nubis PC">
<img class=logo-dark src=/media/logo-nubis-dark.png alt="Nubis PC"></div></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><div class="navbar-logo logo-nubificus"><img class=logo-light src=/media/logo-nubificus_hu_7be4fa6b19286a64.png alt=Nubificus>
<img class=logo-dark src=/media/logo-nubificus-dark_hu_bd80a6d6121ee2ff.png alt=Nubificus></div><div class="navbar-logo logo-nubis"><img class=logo-light src=/media/logo-nubis.png alt="Nubis PC">
<img class=logo-dark src=/media/logo-nubis-dark.png alt="Nubis PC"></div></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/><span>Home</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Research</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/projects/><span>Projects</span></a>
<a class=dropdown-item href=/publication><span>Publications</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Solutions</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/solutions/edgelink/><span>edgeLink</span></a>
<a class=dropdown-item href=/solutions/urunc/><span>urunc</span></a>
<a class=dropdown-item href=/solutions/vaccel/><span>vAccel</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Feed</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/post><span>News</span></a>
<a class=dropdown-item href=/event><span>Events</span></a></div></li><li class=nav-item><a class="nav-link active" href=/blog><span>Blog</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>About</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/people><span>People</span></a>
<a class=dropdown-item href=/contact><span>Contact</span></a></div></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".navbar-nav .nav-item.dropdown");e.forEach(function(t){t.addEventListener("mouseenter",function(){e.forEach(function(e){if(e!==t){e.classList.remove("show");var n=e.querySelector(".dropdown-menu");n&&n.classList.remove("show")}}),t.classList.add("show");var n=t.querySelector(".dropdown-menu");n&&n.classList.add("show")}),t.addEventListener("mouseleave",function(){t.classList.remove("show");var e=t.querySelector(".dropdown-menu");e&&e.classList.remove("show")})})})</script></div><div class=page-body><article class=article><div class=article-container><a class=blog-back-link href=javascript:void(0) onclick=blogGoBack()><i class="fas fa-arrow-left"></i> Back to Blog</a></div><div class="article-container pt-3"><h1>Hardware acceleration in the Age of Functions</h1><div class=article-metadata><span class=article-date>Jun 1, 2020</span></div></div><div class=article-container><div class=article-style><p>The debate on how to deploy applications, monoliths or micro services, is in
full swing. Part of this discussion relates to how the new paradigm
incorporates support for accessing accelerators, e.g. GPUs, FPGAs. That kind
of support has been made available to traditional programming models the last
couple of decades and its tooling has evolved to be stable and standardized.</p><p>On the other hand, what does it mean for a serverless setup to access an
accelerator? Should the function invoked to classify an image, for instance,
link against the whole acceleration runtime and program the hardware device
itself? It seems quite counter-intuitive to create such bloated functions.</p><p>Things get more complicated when we consider the low-level layers of the
service architecture. How does the system itself get access to the
acceleration hardware? Docker allows exposing a GPU device inside a container
for some time now, so serverless systems based on top of it can expose GPU
devices to running functions. Virtual Machine-based setups rely on the
monitor, e.g. QEMU or <a href=https://firecracker-microvm.github.io/ target=_blank rel=noopener>Firecracker</a>, to expose acceleration devices to the
guest.</p><p>There are several techniques used to expose a device from the host to a guest
VM. Passthrough mode exposes the hardware accelerator as is inside the guest.
This mode provides native performance using the accelerator from inside the VM,
however it does cause issues with sharing the device across multiple VMs. API
remoting, e.g. <a href=http://rcuda.net/ target=_blank rel=noopener>rCUDA</a>, is another option, where requests are being
forwarded to the accelerator device over the network. Finally, there is the
option of paravirtual interfaces where the monitor exposes a generic device to
the guest, with a very simple API. Applications in the guest send requests to
the paravirtual device which are then passed to the hypervisor and dispatched
by the latter to an accelerator device on the host.</p><p>VirtIO drivers are an example of such paravirtualized frameworks. VirtIO
exposes simple front-end device drivers to the guest, rather than emulating
complex devices and offloads the complexity of interacting with the hardware
to the back-end that lives in the Virtual Machine Monitor (VMM).</p><h3 id=virtio-crypto>virtio-crypto</h3><p>One of the devices described in the VirtIO spec is the <a href=https://github.com/gongleiarei/virtio target=_blank rel=noopener>virtio-crypto</a>
<a href=https://github.com/gongleiarei/virtio-crypto-linux-driver target=_blank rel=noopener>device</a>. The guest chooses the cryptographic operation to perform and
passes a pointer to the data that will be manipulated. The actual operation is
offloaded through the VMM to the host crypto acceleration device.</p><p>A VM is able to use a crypto device by using a combination of
<em>cryptodev</em> and <em>virtio-crypto</em>. Requests for encryption /
decryption originating from the VM, get forwarded to the backend, get injected
to the <em>cryptodev</em> device and end up being handled by the host Linux
kernel. Figure 1 presents an overview of the <em>virtio-crypto</em>
architecture.</p><figure id=figure-figure-1-virtio-crypto-architecture-overview><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/virtio-crypto.png#center alt="Figure 1: VirtIO-crypto architecture overview" loading=lazy data-zoomable width=60%></div></div><figcaption>Figure 1: VirtIO-crypto architecture overview</figcaption></figure><p>In the context of micro-services (FaaS/Serverless) cryptographic operations are
quite common, presented to the user as language/library abstractions.
Integrating an off-loading mechanism of these CPU-intensive operations seems
like an interesting optimization. To showcase the potential of paravirtual
accelerated devices, we implemented a <em>virtio-crypto</em> backend driver
for AWS Firecracker. Since <em>virtio-crypto</em>&rsquo;s frontend is already present
in the Linux kernel, all we had to do is implement the corresponding back-end
in the Firecracker code base. This effort was relatively straight-forward since
Firecracker already provides a number of VirtIO devices, e.g. net and block,
which means that all the machinery for communication with the guest was in
place.</p><p>Figure 2 shows the performance our <em>virtio-crypto</em> driver achieves (light
bars) compared to running the computation in the guest kernel using the
<em>cryptodev-linux</em> driver (dark bars), when running the AES-CBC cipher.
Unfortunately, we have not been able to get our hands on a crypto acceleration
device, so <em>virtio-crypto</em> is using the same <em>cryptodev-linux</em>
device in the host (the CPU). This means that we do not actually accelerate the
operation, but our experiment is quite useful to see the VirtIO overhead of
offloading the operation to the host. As expected, the larger the block size of
the blob we are encrypting, the better we are able to hide the cost of moving
data from the userland of the guest to the kernel of the host.</p><figure id=figure-figure-2-host-and-guest-throughput-for-aes-cbc-128-vs-chunk-size><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/aes_results.png#center alt="Figure 2: Host and Guest Throughput for AES-CBC-128 vs chunk size" loading=lazy data-zoomable width=80%></div></div><figcaption>Figure 2: Host and Guest Throughput for AES-CBC-128 vs chunk size</figcaption></figure><p>This is encouraging; once there is a hardware accelerator for computation,
acceleration capabilities are automatically exposed inside a Firecracker VM in
a secure way with reasonably low overhead. Which inevitably leads us to the
thought, <em>why only crypto?</em> The <em>virtio-crypto</em> example showcases a
simple interface through which we can achieve hardware acceleration, so why not
generalize this to other types of acceleration?</p><p>This gave us the idea to define a simple, hardware-agnostic API to accelerate
any operation, as long as the host supports it. We believe that an API at this
granularity is the right abstraction for serverless frameworks, since it moves
the complexity of accelerating operations from the guest to the host.</p><h3 id=vaccel>vAccel</h3><p>Let us consider a simple use-case: matrix multiplication. It is a common
operation, used in numerous applications, in HPC, Machine Learning, and Big
Data. In the generic case, the user running the application on a VM would
have to either have access to the GPU hardware and enjoy hardware acceleration,
or perform the operation on the CPU, wasting time and CPU cycles.</p><p>Instead of passing through the GPU hardware, we choose a different
path: we introduce vAccel, a simple paravirtual framework that forwards
operation requests to the monitor, which, in turn, uses native calls to an
acceleration framework, taking advantage of the hardware capabilities of the
host.</p><p>The vAccel framework allows workloads that execute on Virtual Machines to
offload compute-intensive functions to backends provided by the hypervisor. To
achieve this, the system presents a number of host-side accelerator functions
to the guest kernel, which are backed by hardware accelerators (FPGAs, GPUs,
specialized crypto engines etc.).</p><p>vAccel consists of three main parts: the frontend driver, the backend driver
and the runtime. An overview of the system architecture is shown in Figure 3.</p><figure id=figure-figure-3-vaccel-architecture-overview><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/vaccel.png#center alt="Figure 3: vAccel architecture overview" loading=lazy data-zoomable width=70%></div></div><figcaption>Figure 3: vAccel architecture overview</figcaption></figure><p>Frontend and Backend drivers implement the transport layer. We base our
implementation on VirtIO, and follow the generic VirtIO spec, using a single
queue for control and data exchange.</p><p>The runtime includes two components: a <em>host library</em> that handles
offload requests, and a <em>guest library</em> that intercepts the actual
offload-able user calls and creates those requests.</p><p>The basic API is given below:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=k>typedef</span> <span class=kt>uint8_t</span> <span class=kt>vaccel_op_t</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/* Get available accelerate-able operations from the backend */</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>vaccel_get_operations</span><span class=p>(</span><span class=kt>uint8_t</span> <span class=o>*</span><span class=n>available_operations</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/* Start a new session */</span>
</span></span><span class=line><span class=cl><span class=kt>vaccel_session_t</span> <span class=o>*</span><span class=nf>create_vaccel_session</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/* Invoke an acceleration operation */</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>do_operation</span><span class=p>(</span><span class=kt>vaccel_session_t</span> <span class=o>*</span><span class=n>handle</span><span class=p>,</span> <span class=kt>vaccel_op_t</span> <span class=n>operation</span><span class=p>,</span> <span class=kt>void</span> <span class=o>*</span><span class=n>input</span><span class=p>,</span> <span class=kt>void</span> <span class=o>*</span><span class=n>output</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=cm>/* End a running session */</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>destory_vaccel_session</span><span class=p>(</span><span class=kt>vaccel_session_t</span> <span class=o>*</span><span class=n>handle</span><span class=p>);</span>
</span></span></code></pre></div><p>To study the potential overhead of such an approach on a common function, we
deploy a generic QEMU/KVM VM on an x86 host, using an FPGA card as the
accelerator (<a href=http://www.netlib.org/lapack/explore-html/db/dc9/group__single__blas__level3_gafe51bacb54592ff5de056acabd83c260.html target=_blank rel=noopener>SGEMM</a>, implemented with OpenCL). We run the stencil on the host to
obtain a baseline, and then we execute the same benchmark on the vAccel-enabled
guest and capture the results.</p><figure id=figure-figure-4-sgemm-host--guest-results-vs-matrix-size><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/sgemm.png#center alt="Figure 4: SGEMM Host / Guest results vs matrix size" loading=lazy data-zoomable width=80%></div></div><figcaption>Figure 4: SGEMM Host / Guest results vs matrix size</figcaption></figure><p>Figure 4 presents the performance of SGEMM on a single core VM (light bars)
against the respective run on the host (dark bars) for various matrix sizes.
On the Y axis we plot the MFlops achieved by the SGEMM stencil, while on the X
axis we lay the size of the matrices tested. For large matrix sizes (>
128x128), the overhead perceived by the user is minimal, ranging from 16% to
even &lt;3%.</p><h3 id=inference-at-the-edge>Inference at the edge</h3><p>Let us now consider a more complicated scenario: image classification. From the
user perspective it is a simple operation: (i) provide an image as input, (ii)
define which model will be used to classify the image, (iii) wait for the
result. However, the system internals are a bit more complicated: the image has
to be preprocessed, fed to a pre-trained classification model, and mapped to a
given set of labels. This abstraction is already provided by common frameworks
such as Tensorflow, Caffe etc. However, these frameworks perform optimally with
direct access to hardware accelerators. Figure 5 presents the path to the
hardware accelerator from the VM&rsquo;s userspace.</p><figure id=figure-figure-5-inference-use-case><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/ml_legacy.png#center alt="Figure 5: Inference use-case" loading=lazy data-zoomable width=80%></div></div><figcaption>Figure 5: Inference use-case</figcaption></figure><p>We use vAccel to expose accelerated inference capabilities to a guest VM.
Specifically, we expose one basic function, image classification. The guest
simply issues a request with the image to be classified and the model to be
used for inference. The backend forwards this request to vAccel-runtime, which,
in turn, calls wrapper functions on top of the Tensorflow runtime to classify
the image. The result is copied back to the guest synchronously. Figure 6
presents the vAccel-enabled path.</p><figure id=figure-figure-6-inference-use-case-with-vaccel><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/ml_vaccel.png#center alt="Figure 6: Inference use-case with vAccel" loading=lazy data-zoomable width=80%></div></div><figcaption>Figure 6: Inference use-case with vAccel</figcaption></figure><p>Figure 7 plots the total execution time of an image classification operation
for various image sizes deployed on a generic QEMU/KVM VM on an <a href=https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/ target=_blank rel=noopener>NVIDIA Jetson
Nano</a>. Dark bars indicate the time required to complete the operation on
the host, whereas light bars show the respective time spent on the guest.
Clearly, the overhead is minimal: the average overhead across all cases is 1%.</p><figure id=figure-figure-7-image-classification-with-vaccel><div class="d-flex justify-content-center"><div class=w-100><img src=/images/vaccel/ml_results.png#center alt="Figure 7: Image classification with vAccel" loading=lazy data-zoomable width=80%></div></div><figcaption>Figure 7: Image classification with vAccel</figcaption></figure><p>As execution moves to the Edge, following the Serverless paradigm, efficiency
is key to provide low power consumption, while at the same time increase the
quality and the diversity of services offered to the end user. Offloading
computation to specialized units is one of the most important aspects to
balance trade-offs related to resource utilization and energy-efficiency and
to minimize request-response latency.</p><p><em>vAccel is being developed jointly by the <a href=http://research.cslab.ece.ntua.gr target=_blank rel=noopener>Computing Systems Laboratory</a> of
the <a href=https://www.ntua.gr target=_blank rel=noopener>National Technical University of Athens</a> and <a href=https://nubificus.co.uk target=_blank rel=noopener>Nubificus LTD</a>.
vAccel is open-source and WiP; we plan to provide an RFC for the frontend
driver to be upstreamed, as well as respective RFCs for the backends (QEMU,
Firecracker etc.).</em></p></div><div class=article-tags><a class="badge badge-light" href=/tag/vaccel/>VAccel</a>
<a class="badge badge-light" href=/tag/virtio/>VirtIO</a>
<a class="badge badge-light" href=/tag/qemu/>QEMU</a>
<a class="badge badge-light" href=/tag/serverless/>Serverless</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=%2Fblog%2Fvaccel%2F&amp;text=Hardware+acceleration+in+the+Age+of+Functions" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=%2Fblog%2Fvaccel%2F&amp;t=Hardware+acceleration+in+the+Age+of+Functions" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Hardware%20acceleration%20in%20the%20Age%20of%20Functions&amp;body=%2Fblog%2Fvaccel%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=%2Fblog%2Fvaccel%2F&amp;title=Hardware+acceleration+in+the+Age+of+Functions" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Hardware+acceleration+in+the+Age+of+Functions%20%2Fblog%2Fvaccel%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=%2Fblog%2Fvaccel%2F&amp;title=Hardware+acceleration+in+the+Age+of+Functions" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></article><script>function blogGoBack(){document.referrer&&document.referrer.indexOf("/blog")!==-1?history.back():window.location.href="/blog/"}</script></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2026 Nubificus LTD. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.6782e3f6a4f06ea4766df038c45ecf40.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.b95a7e109243f29d04930ae8cb49a756.js type=module></script><script src=/en/js/wowchemy.min.ed487406ecbb80985462ba7a97b6f2d2.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js type=module></script></body></html>